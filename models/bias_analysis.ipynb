{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'no_protected_model'  # Folder in results containing data and where analysis will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load(f'results/{folder}/pred.npy')\n",
    "testX = np.load(f'results/{folder}/testX.npy')\n",
    "testY = np.load(f'results/{folder}/testY.npy')\n",
    "print(f\"Shapes: {preds.shape}, {testX.shape}, {testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import partially preprocessed version so there aren't too many columns\n",
    "test_df = pd.read_csv('dataset/test_split_partially_preprocessed.csv')\n",
    "# test_df = pd.read_csv('dataset/test_preprocessed.csv')  # Full dataset\n",
    "\n",
    "# Add truncation (since this wasn't done for partially_preprocessed version)\n",
    "test_df.loc[test_df.INCWAGE_CPIU_2010 > 100000, 'INCWAGE_CPIU_2010'] = 100000\n",
    "\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(testY).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures that the indices are correct\n",
    "assert((test_df.INCWAGE_CPIU_2010 == pd.Series(testY)).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if SERIAL or PERNUM are in testX\n",
    "# for i in range(testX.shape[1]):\n",
    "#     seriesConverted = pd.Series(testX[:,i])\n",
    "#     if (test_df.SERIAL == seriesConverted).all():\n",
    "#         print(f\"Column {i} is SERIAL\")\n",
    "#     if (test_df.PERNUM == seriesConverted).all():\n",
    "#         print(f\"Column {i} is PERNUM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Old shape: \", test_df.shape)\n",
    "test_df['Income_Pred'] = preds\n",
    "print(\"New shape: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are metrics with no rounding\n",
    "test_df['Income_Pred'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Income_Pred'] = test_df['Income_Pred'].round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are metrics with rounding\n",
    "test_df['Income_Pred'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for biases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create underprediction/overprediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of predictions that are perfect\n",
    "(test_df.Income_Pred.round(0) == test_df.INCWAGE_CPIU_2010).values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Pred_Error'] = test_df['Income_Pred'] - test_df['INCWAGE_CPIU_2010']\n",
    "test_df['Pred_Error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Pred_AbsError'] = test_df['Pred_Error'].abs()\n",
    "test_df['Pred_AbsError'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Income summary\")\n",
    "print(test_df.INCWAGE_CPIU_2010.describe())\n",
    "print(\"\\nIncome prediction summary\")\n",
    "print(test_df.Income_Pred.describe())\n",
    "print(\"\\nAbsolute error summary\")\n",
    "print(test_df.Pred_AbsError.describe())\n",
    "print(\"\\nRelative error summary\")\n",
    "print(test_df.Pred_Error.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~full_df.isWhite).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isWhite.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isWhite.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isWhite.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isAsian.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.isWhite.sum() / len(full_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test differences in accuracy and under/overprediction rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_cols = [\n",
    "    'isFemale', \n",
    "    'isAmericanIndian', 'isAsian', 'isBlack', 'isPacificIslander', 'isWhite', 'isOtherRace', 'isHispanic',\n",
    "    'bornInUS',\n",
    "    'isMarried', 'wasMarried', 'neverMarried',\n",
    "    'sameSexMarriage', 'mixedRaceMarriage',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRows = len(test_df)  # Total number of rows in the dataset\n",
    "summaryEntries = 0  # Number of entries in the summary\n",
    "\n",
    "with open(f'results/{folder}/analysis/summary1.txt', 'w') as f:\n",
    "    for col in protected_cols:\n",
    "        if test_df[col].dtype != 'bool':\n",
    "            raise Exception(f\"Column {col} is not boolean\")\n",
    "\n",
    "        assert(not test_df[col].isna().values.any())\n",
    "\n",
    "        numTrue = test_df[col].values.sum()  # Number of entries for which the column is true\n",
    "        numFalse = totalRows - numTrue  # Number of entries for which the column is false\n",
    "\n",
    "        dfTrue = test_df[test_df[col]]\n",
    "        dfFalse = test_df[~test_df[col]]\n",
    "\n",
    "        print(f'Of the people for whom {col} is true ({numTrue} of {totalRows} entries, or {numTrue / totalRows * 100}%), actual salaries are:')\n",
    "        print(dfTrue.INCWAGE_CPIU_2010.describe())\n",
    "        print(\"Predictions are\")\n",
    "        print(dfTrue.Income_Pred.describe())\n",
    "        print(\"Absolute error is:\")\n",
    "        print(dfTrue.Pred_AbsError.describe())\n",
    "        print(\"Relative error is:\")\n",
    "        print(dfTrue.Pred_Error.describe())\n",
    "        print(\"\\n\")\n",
    "        print(f'Of the people for whom {col} is false ({numFalse} of {totalRows} entries, or {numFalse / totalRows * 100}%), actual salaries are:')\n",
    "        print(dfFalse.INCWAGE_CPIU_2010.describe())\n",
    "        print(\"Predictions are\")\n",
    "        print(dfFalse.Income_Pred.describe())\n",
    "        print(\"Absolute error is:\")\n",
    "        print(dfFalse.Pred_AbsError.describe())\n",
    "        print(\"Relative error is:\")\n",
    "        print(dfFalse.Pred_Error.describe())\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # Look for interesting cases to add to summary\n",
    "\n",
    "        # Large difference in mean prediction\n",
    "        if(abs(dfTrue.Income_Pred.mean() - dfFalse.Income_Pred.mean()) > 1000):\n",
    "            f.write(f\"Mean prediction for {col} is significantly different than mean prediction for not {col}\\n\")\n",
    "            f.write(f\"Mean prediction for {col}: {dfTrue.Income_Pred.mean()}\")\n",
    "            f.write(f\"\\tMean prediction for not {col}: {dfFalse.Income_Pred.mean()}\")\n",
    "            f.write(\"\\n\\n\")\n",
    "            summaryEntries += 1\n",
    "        # Large difference in mean absolute error\n",
    "        if(abs(dfTrue.Pred_AbsError.mean() - dfFalse.Pred_AbsError.mean()) > 1000):\n",
    "            f.write(f\"Mean absolute error for {col} is significantly different than mean absolute error for not {col}\\n\")\n",
    "            f.write(f\"Mean absolute error for {col}: {dfTrue.Pred_AbsError.mean()}\")\n",
    "            f.write(f\"\\tMean absolute error for not {col}: {dfFalse.Pred_AbsError.mean()}\")\n",
    "            f.write(\"\\n\\n\")\n",
    "            summaryEntries += 1\n",
    "        # Large difference in mean relative error\n",
    "        if(abs(dfTrue.Pred_Error.mean() - dfFalse.Pred_Error.mean()) > 750):\n",
    "            f.write(f\"Mean relative error for {col} is significantly different than mean relative error for not {col}\\n\")\n",
    "            f.write(f\"Mean relative error for {col}: {dfTrue.Pred_Error.mean()}\")\n",
    "            f.write(f\"\\tMean relative error for not {col}: {dfFalse.Pred_Error.mean()}\")\n",
    "            f.write(\"\\n\\n\")\n",
    "            summaryEntries += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryEntries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.AGE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age distribution for people who are married\")\n",
    "print(test_df[test_df.isMarried].AGE.describe())\n",
    "print(\"Income distribution for people who are married\")\n",
    "print(test_df[test_df.isMarried].INCWAGE_CPIU_2010.describe())\n",
    "print(\"\\nAge distribution for people who are not married\")\n",
    "print(test_df[~test_df.isMarried].AGE.describe())\n",
    "print(\"Income distribution for people who are not married\")\n",
    "print(test_df[~test_df.isMarried].INCWAGE_CPIU_2010.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age distribution for people who were married\")\n",
    "print(test_df[test_df.wasMarried].AGE.describe())\n",
    "print(\"Income distribution for people who were married\")\n",
    "print(test_df[test_df.wasMarried].INCWAGE_CPIU_2010.describe())\n",
    "print(\"\\nAge distribution for people who were not married\")\n",
    "print(test_df[~test_df.wasMarried].AGE.describe())\n",
    "print(\"Income distribution for people who were not married\")\n",
    "print(test_df[~test_df.wasMarried].INCWAGE_CPIU_2010.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = test_df.copy()\n",
    "age_cols = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    col = f'age_{i*10}To{(i+1)*10}'\n",
    "    print(f'Of the people for whom {col} is true, income is')\n",
    "    print(test_df[(test_df.AGE >= i*10) & (test_df.AGE < (i+1)*10)].INCWAGE_CPIU_2010.describe())\n",
    "    print(f'Of the people for whom {col} is false, income is')\n",
    "    print(test_df[(test_df.AGE < i*10) | (test_df.AGE >= (i+1)*10)].INCWAGE_CPIU_2010.describe())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df.isFemale].INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[~test_df.isFemale].INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in test_df.columns if 'DEGFIELD' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train_split_partially_preprocessed.csv')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df, test_df])\n",
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ratio are women:\", full_df.isFemale.values.sum() / full_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number with business degree\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum() / len(full_df))\n",
    "print(\"Ratio women:\", (full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum() / ((~full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum()+(full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number with engineering degree\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum() / len(full_df))\n",
    "print(\"Ratio women:\", (full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum() / ((~full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum()+(full_df.isFemale & (full_df.DEGFIELD == 24)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number with some college\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.someCollege)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.someCollege)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.someCollege)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.someCollege)).values.sum() / len(full_df))\n",
    "print(\"Ratio are women:\", (full_df.isFemale & (full_df.someCollege)).values.sum() / ((~full_df.isFemale & (full_df.someCollege)).values.sum()+(full_df.isFemale & (full_df.someCollege)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number working in california\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum() / len(full_df))\n",
    "print(\"Ratio are women:\", (full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum() / ((~full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum()+(full_df.isFemale & (full_df.PWSTATE2 == 6)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number working as \"Chief executives and legislators/public administration\"\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.OCC2010 == 10)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.OCC2010 == 10)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.OCC2010 == 10)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.OCC2010 == 10)).values.sum() / len(full_df))\n",
    "print(\"Ratio of women:\", (full_df.isFemale & (full_df.OCC2010 == 10)).values.sum() / ((~full_df.isFemale & (full_df.OCC2010 == 10)).values.sum()+(full_df.isFemale & (full_df.OCC2010 == 10)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number working as \"Physicians and Surgeons\"\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum() / len(full_df))\n",
    "print(\"Ratio of women:\", (full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum() / ((~full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum()+(full_df.isFemale & (full_df.OCC2010 == 3060)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are codes and names of jobs that were prioritized by the model in the shap analysis\n",
    "shapOccs = [\n",
    "    (430, \"Managers, nec (including Postmasters)\"),\n",
    "    (3130, \"Registered nurses\"),\n",
    "    (10, \"Chief executives and legislators/public administration\"),\n",
    "    (3060, \"Physicians and Surgeons\"),\n",
    "    ((4840, 4850), \"Sales Representatives\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for occNum, occName in shapOccs:\n",
    "    print(occNum, type(occNum) is tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceCols = ['isWhite', 'isBlack', 'isAsian', 'isAmericanIndian', 'isPacificIslander', 'isOtherRace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in full_df.columns if 'School' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for occNum, occName in shapOccs:\n",
    "    print(f\"For occupation {occName}:\")\n",
    "    if type(occNum) is tuple:\n",
    "        assert(len(occNum) == 2), \"occNum must be a tuple of length 2\"\n",
    "        occDf = full_df[(full_df.OCC2010 == occNum[0]) | (full_df.OCC2010 == occNum[1])]\n",
    "    else:\n",
    "        occDf = full_df[full_df.OCC2010 == occNum]\n",
    "    print(\"Number women:\", occDf.isFemale.values.sum(), \n",
    "        # \"\\tNumber men:\", (~occDf.isFemale).values.sum(), \n",
    "        \"\\tPercent women:\", occDf.isFemale.values.sum() / len(occDf)\n",
    "    )\n",
    "\n",
    "    for race in raceCols:\n",
    "        print(f\"Number {race}:\", occDf[race].values.sum(), f\"\\tPercent {race}:\", occDf[race].values.sum() / len(occDf))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are codes and names of jobs that were prioritized by the model in the shap analysis\n",
    "shapDegrees = [\n",
    "    (62, \"Business\"),\n",
    "    (24, \"Engineering\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degNum, degName in shapDegrees:\n",
    "    print(f\"For degree {degName}:\")\n",
    "    degDf = full_df[full_df.DEGFIELD == degNum]\n",
    "    print(\"Number women:\", degDf.isFemale.values.sum(),\n",
    "        \"\\tPercent women:\", degDf.isFemale.values.sum() / len(degDf)\n",
    "    )\n",
    "\n",
    "    for race in raceCols:\n",
    "        print(f\"Number {race}:\", degDf[race].values.sum(), f\"\\tPercent {race}:\", degDf[race].values.sum() / len(degDf))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[full_df.isSelfEmployed].INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[~full_df.isSelfEmployed].INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "someCollegeDf = full_df[full_df.someCollege]\n",
    "notSomeCollegeDf = full_df[~full_df.someCollege]\n",
    "\n",
    "print(\"For someCollege=True:\")\n",
    "print(\"Number women:\", someCollegeDf.isFemale.values.sum(),\n",
    "    \"\\tPercent women:\", someCollegeDf.isFemale.values.sum() / len(someCollegeDf)\n",
    ")\n",
    "\n",
    "for race in raceCols:\n",
    "    print(f\"Number {race}:\", someCollegeDf[race].values.sum(), \n",
    "        f\"\\tPercent {race}:\", someCollegeDf[race].values.sum() / len(someCollegeDf)\n",
    "    )\n",
    "\n",
    "print(\"\\nFor someCollege=False:\")\n",
    "print(\"Number women:\", notSomeCollegeDf.isFemale.values.sum(),\n",
    "    \"\\tPercent women:\", notSomeCollegeDf.isFemale.values.sum() / len(notSomeCollegeDf)\n",
    ")\n",
    "\n",
    "for race in raceCols:\n",
    "    print(f\"Number {race}:\", notSomeCollegeDf[race].values.sum(), \n",
    "        f\"\\tPercent {race}:\", notSomeCollegeDf[race].values.sum() / len(notSomeCollegeDf)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in full_df.columns if 'Sales_Representative' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_df.OCC2010 == 4850).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in full_df.columns if 'English' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~full_df.speaksEnglish & ~full_df.speaksOnlyEnglish & ~full_df.speaksEnglishWell).values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number working as \"Registered nurses\"\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum() / len(full_df))\n",
    "print(\"Ratio of women:\", (full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum() / ((~full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum()+(full_df.isFemale & (full_df.OCC2010 == 3130)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number working as \"Chief executives and legislators/public administration\"\n",
    "print(\"Women:\", (full_df.isFemale & (full_df.OCC2010 == 10)).values.sum())\n",
    "print(\"Men:\", (~full_df.isFemale & (full_df.OCC2010 == 10)).values.sum())\n",
    "print(\"Percent are women:\", (full_df.isFemale & (full_df.OCC2010 == 10)).values.sum() / len(full_df))\n",
    "print(\"Percent are men:\", (~full_df.isFemale & (full_df.OCC2010 == 10)).values.sum() / len(full_df))\n",
    "print(\"Ratio of women:\", (full_df.isFemale & (full_df.OCC2010 == 10)).values.sum() / ((~full_df.isFemale & (full_df.OCC2010 == 10)).values.sum()+(full_df.isFemale & (full_df.OCC2010 == 10)).values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~full_df.isFemale & (full_df.DEGFIELD == 62)).values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[full_df.someCollege].INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[~full_df.someCollege].INCWAGE_CPIU_2010.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRows = len(test_df)  # Total number of rows in the dataset\n",
    "summaryEntries = 0  # Number of entries in the summary\n",
    "\n",
    "with open(f'results/{folder}/analysis/summary1.txt', 'w') as f:\n",
    "    for col in protected_cols:\n",
    "        if test_df[col].dtype != 'bool':\n",
    "            raise Exception(f\"Column {col} is not boolean\")\n",
    "\n",
    "        assert(not test_df[col].isna().values.any())\n",
    "\n",
    "        numTrue = test_df[col].values.sum()  # Number of entries for which the column is true\n",
    "        numFalse = totalRows - numTrue  # Number of entries for which the column is false\n",
    "\n",
    "        dfTrue = test_df[test_df[col]]\n",
    "        dfFalse = test_df[~test_df[col]]\n",
    "\n",
    "        print(f'Of the people for whom {col} is true ({numTrue} of {totalRows} entries, or {numTrue / totalRows * 100}%), actual salaries are:')\n",
    "        print(dfTrue.INCWAGE_CPIU_2010.describe())\n",
    "        print(\"Predictions are\")\n",
    "        print(dfTrue.Income_Pred.describe())\n",
    "        print(\"Absolute error is:\")\n",
    "        print(dfTrue.Pred_AbsError.describe())\n",
    "        print(\"Relative error is:\")\n",
    "        print(dfTrue.Pred_Error.describe())\n",
    "        print(\"\\n\")\n",
    "        print(f'Of the people for whom {col} is false ({numFalse} of {totalRows} entries, or {numFalse / totalRows * 100}%), actual salaries are:')\n",
    "        print(dfFalse.INCWAGE_CPIU_2010.describe())\n",
    "        print(\"Predictions are\")\n",
    "        print(dfFalse.Income_Pred.describe())\n",
    "        print(\"Absolute error is:\")\n",
    "        print(dfFalse.Pred_AbsError.describe())\n",
    "        print(\"Relative error is:\")\n",
    "        print(dfFalse.Pred_Error.describe())\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        # Look for interesting cases to add to summary\n",
    "\n",
    "        # Large difference in mean prediction\n",
    "        if(abs(dfTrue.Income_Pred.mean() - dfFalse.Income_Pred.mean()) > 1000):\n",
    "            f.write(f\"Mean prediction for {col} is significantly different than mean prediction for not {col}\\n\")\n",
    "            f.write(f\"Mean prediction for {col}: {dfTrue.Income_Pred.mean()}\")\n",
    "            f.write(f\"\\tMean prediction for not {col}: {dfFalse.Income_Pred.mean()}\")\n",
    "            f.write(\"\\n\\n\")\n",
    "            summaryEntries += 1\n",
    "        # Large difference in mean absolute error\n",
    "        if(abs(dfTrue.Pred_AbsError.mean() - dfFalse.Pred_AbsError.mean()) > 1000):\n",
    "            f.write(f\"Mean absolute error for {col} is significantly different than mean absolute error for not {col}\\n\")\n",
    "            f.write(f\"Mean absolute error for {col}: {dfTrue.Pred_AbsError.mean()}\")\n",
    "            f.write(f\"\\tMean absolute error for not {col}: {dfFalse.Pred_AbsError.mean()}\")\n",
    "            f.write(\"\\n\\n\")\n",
    "            summaryEntries += 1\n",
    "        # Large difference in mean relative error\n",
    "        if(abs(dfTrue.Pred_Error.mean() - dfFalse.Pred_Error.mean()) > 750):\n",
    "            f.write(f\"Mean relative error for {col} is significantly different than mean relative error for not {col}\\n\")\n",
    "            f.write(f\"Mean relative error for {col}: {dfTrue.Pred_Error.mean()}\")\n",
    "            f.write(f\"\\tMean relative error for not {col}: {dfFalse.Pred_Error.mean()}\")\n",
    "            f.write(\"\\n\\n\")\n",
    "            summaryEntries += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
