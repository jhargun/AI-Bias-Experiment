{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('dataset/init_preprocessed_data_without_index.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns with each type\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop rows where PWSTATE2 is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nostate = (df.PWSTATE2 == 0).values.sum()\n",
    "original_len = len(df)\n",
    "print(f\"{num_nostate} ({num_nostate/original_len:.2%}) of the rows have no state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with no state\n",
    "df = df[df.PWSTATE2 != 0].copy()\n",
    "assert(len(df) == original_len - num_nostate)\n",
    "print(f\"Removed {num_nostate} rows with no state. {len(df)} rows remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are now unnecessary\n",
    "\n",
    "origNumCols = len(df.columns)\n",
    "droppedCols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    unique = df[col].unique()\n",
    "    if(len(unique) == 1):\n",
    "        print(f\"Dropping column {col} since it has only one value: {unique[0]}\")\n",
    "        droppedCols.append(col)\n",
    "    elif(len(unique) == 2 and df[col].isna().values.any()):\n",
    "        print(f\"Warning: Column {col} has two values but you may still want to drop it: {unique[0]} and {unique[1]}\")\n",
    "\n",
    "df.drop(droppedCols, axis=1, inplace=True)\n",
    "assert(len(df.columns) == origNumCols - len(droppedCols))\n",
    "print(f\"Dropped {len(droppedCols)} columns. {len(df.columns)} columns remain.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop additional unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['YRMARR', 'YRNATUR'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use random_state=0 to get the same split every time\n",
    "train, test = train_test_split(df, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we check that each column in train and test has the same number of unique values as the original column in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    # These columns don't need to be checked\n",
    "    if col in ['SERIAL', 'PERNUM', 'HHWT', 'CLUSTER', 'STRATA', 'PERWT', 'UHRSWORK', 'TRANTIME', 'INCWAGE_CPIU_2010']:\n",
    "        continue\n",
    "    \n",
    "    originalUnique = df[col].unique()\n",
    "    trainUnique = train[col].unique()\n",
    "    testUnique = test[col].unique()\n",
    "\n",
    "    if(len(originalUnique) != len(trainUnique) or len(originalUnique) != len(testUnique)):\n",
    "        print(f\"Warning: Values of {col} in train ({trainUnique}) and test ({testUnique}) are not the same as in the original ({originalUnique})\")\n",
    "        raise Exception(\"Values of column in train and test are not the same as in the original\")\n",
    "    \n",
    "    elif(len(originalUnique) == 2):\n",
    "        for trainNum, testNum in zip(train[col].value_counts().tolist(), test[col].value_counts().tolist()):\n",
    "            testRatio = testNum / len(test)\n",
    "            trainRatio = trainNum / len(train)\n",
    "            if(testRatio > trainRatio+.01 or testRatio < trainRatio-.01):\n",
    "                print(f\"Warning: Ratio of {col} values in train ({trainRatio}) and test ({testRatio}) are not the same\")\n",
    "                raise Exception(\"Ratio of values of column in train and test are not the same as in the original\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('dataset/train_split_partially_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('dataset/test_split_partially_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a60c63dd419133ec943074489a186d09dce25069fc0d4ed86e3ad3c69baefe89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
