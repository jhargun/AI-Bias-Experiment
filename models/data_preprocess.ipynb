{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('usa_00003.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about memory usage of df\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns with each type\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set indices\n",
    "\n",
    "The SAMPLE and SERIAL columns can uniquely identify every household, which when combined with PERNUM (a number that uniquely identifies members in each household) can uniquely identify each person. Since all data is from the same 2021 sample, SAMPLE is unnecessary. Therefore, SERIAL and PERNUM are used as indices (after being downcast to uint dtype in order to use less memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(preprocessed_df.SERIAL.min() >= 0 and preprocessed_df.PERNUM.min() >= 0)\n",
    "preprocessed_df.SERIAL = pd.to_numeric(preprocessed_df.SERIAL, downcast='unsigned')\n",
    "preprocessed_df.PERNUM = pd.to_numeric(preprocessed_df.PERNUM, downcast='unsigned')\n",
    "print(\"New datatypes: SERIAL: {}, PERNUM: {}\".format(preprocessed_df.SERIAL.dtype, preprocessed_df.PERNUM.dtype))\n",
    "preprocessed_df.set_index(['SERIAL', 'PERNUM'], inplace=True)\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnecessary columns\n",
    "\n",
    "These columns don't encode any useful data and are therefore dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All samples are from 2021 IPUMS data, so year and sample columns are unnecessary\n",
    "unnecessary_columns = ['YEAR', 'SAMPLE']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "for col in unnecessary_columns:\n",
    "    if col in preprocessed_df.columns:\n",
    "        assert(len(preprocessed_df[col].unique()) == 1)\n",
    "        print('Dropping {} column; original value: {}'.format(col, preprocessed_df[col][0]))\n",
    "        preprocessed_df.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should print nothing after previous cell is run. If it prints anything, you can probably drop that column.\n",
    "for col in preprocessed_df.columns:\n",
    "    unique = preprocessed_df[col].unique()\n",
    "    if len(unique) == 1:\n",
    "        print(col, unique)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Quality Columns\n",
    "\n",
    "Data quality columns give information about whether the response was altered by staff. The method of this alteration is generally not specified. These columns are dropped because they are unnecessary when training the model (though they can be useful for analyzing potential discrepancies in data).\n",
    "\n",
    "Note that the original data contains 44 data quality flags, so this many columns should be dropped by the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = 0\n",
    "for col in preprocessed_df.columns:\n",
    "    if col[0] == 'Q':\n",
    "        if col[1:] not in preprocessed_df.columns:\n",
    "            print(\"{} dropped but no column {} exists. Make sure this isn't an error.\".format(col, col[1:]))\n",
    "        preprocessed_df.drop([col], axis=1, inplace=True)\n",
    "        dropped += 1\n",
    "print('Dropped {} columns'.format(dropped))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess columns\n",
    "\n",
    "The below section will preprocess columns in order to make data easier to understand and to reduce memory usage. Each cell processes a different column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess binary columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get a list of columns with 2 unique values (which can be turned into boolean columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all columns with 2 unique values (can convert to boolean columns)\n",
    "for col in preprocessed_df.columns:\n",
    "    unique = preprocessed_df[col].unique()\n",
    "    if len(unique) == 2:\n",
    "        print('{} ({}): {}'.format(col, preprocessed_df[col].dtype, len(unique)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, preprocess any columns that should have NaN values (this is necessary as often responses that should be NaN such as no response or N/A are instead coded as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.SCHOOL.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of columns that will be converted to boolean columns. Each tuple contains the current column name, the name of the boolean column that it'll be converted to, and a boolean that determines whether the column will be dropped when the boolean column is created. Unless you have a good reason to keep the original column, you should drop it once the boolean column is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples containing current column name, new boolean column name, and whether to drop current column when new column created\n",
    "boolean_column_conversions = [\n",
    "    # SEX is 1 if male, 2 if female (no other options)\n",
    "    ('SEX', 'isFemale', False),\n",
    "\n",
    "    # These columns store binary race (single person can have multiple races, RACNUM stores how many races single person selected)\n",
    "    ('RACAMIND', 'isAmericanIndian', True),\n",
    "    ('RACASIAN', 'isAsian', True),\n",
    "    ('RACBLK', 'isBlack', True),\n",
    "    ('RACPACIS', 'isPacificIslander', True),\n",
    "    ('RACWHT', 'isWhite', True),\n",
    "    ('RACOTHER', 'isOtherRace', True),\n",
    "\n",
    "    # These columns store information about health insurance coverage\n",
    "\n",
    "    # Private includes HINSEMP, HINSPUR, and HINSTRI\n",
    "    ('HCOVPRIV', 'hasPrivateHealthInsurance', True),\n",
    "    # Includes current/former employers or union health insurance; or those covered by family's insurance provided by these groups\n",
    "    ('HINSEMP', 'hasEmployerHealthInsurance', True),\n",
    "    # Includes health insurance purchased directly by individual or family\n",
    "    ('HINSPUR', 'hasPurchasedPrivHealthInsurance', True),\n",
    "    # Includes TRICARE and other military health program\n",
    "    ('HINSTRI', 'hasMilitaryHealthInsurance', True),\n",
    "\n",
    "    # Public includes HINSCARE, HINSCAID, HINSVA\n",
    "    ('HCOVPUB', 'hasPublicHealthInsurance', True),\n",
    "    ('HINSCARE', 'hasMedicare', True),\n",
    "    # Includes Medicaid, Medical Assistance, or other government plans for those w/ low income or disability\n",
    "    ('HINSCAID', 'hasMedicaid', True),\n",
    "    ('HINSVA', 'hasVeteransHealthInsurance', True),  # Includes all who have ever used/enrolled for VA health care\n",
    "\n",
    "    ('HINSIHS', 'hasIndianHealthInsurance', True),  # Includes those getting insurance through Indian Health Service\n",
    "\n",
    "    # HCOVANY includes HINSEMP, HINSPUR, HINSTRI, HINSCARE, HINSCAID, HINSVA\n",
    "    # Indian Health Services insurance not included in HCOVANY (since IPUMS says IHS policies not always comprehensive)\n",
    "    ('HCOVANY', 'hasHealthInsurance', True),\n",
    "\n",
    "    # Whether respondant is currently in school\n",
    "    ('SCHOOL', 'isInSchool', True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, new_col, drop_col in boolean_column_conversions:\n",
    "    if col in preprocessed_df.columns:\n",
    "        assert(len(preprocessed_df[col].unique()) == 2)\n",
    "        if(preprocessed_df[col].isnull().values.any()):\n",
    "            print('Warning: {} has null values. This means {} will have null values. Make sure this is expected.'.format(col, new_col))\n",
    "        preprocessed_df[new_col] = (preprocessed_df[col] - 1).astype(\"boolean\")\n",
    "        if drop_col:\n",
    "            preprocessed_df.drop([col], axis=1, inplace=True)\n",
    "    elif new_col not in preprocessed_df.columns:\n",
    "        print('Warning: {} not in preprocessed_df so {} not generated'.format(col, new_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~(preprocessed_df.SCHOOL.replace(0, np.nan) - 1).astype(\"boolean\")).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preprocessed_df.SCHOOL.replace(0, np.nan) - 1).astype(\"boolean\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preprocessed_df.SCHOOL.replace(0, np.nan) - 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess HISPAN column into isHispanic boolean column. Dropping HISPAN and HISPAND (detailed version of HISPAN) removes information about Hispanic respondants' specific background, so don't drop these columns if you want to preserve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISPAN column is 0 if not Hispanic, nonzero if Hispanic\n",
    "\n",
    "# 9 represents unknown value. Shouldn't be present in our data.\n",
    "assert(9 not in preprocessed_df.HISPAN.values)\n",
    "\n",
    "preprocessed_df['isHispanic'] = preprocessed_df.HISPAN.astype(bool)\n",
    "\n",
    "# Drop these if you don't care about details. HISPAND is more detailed version of HISPAND\n",
    "preprocessed_df.drop(['HISPAN'], axis=1, inplace=True)\n",
    "preprocessed_df.drop(['HISPAND'], axis=1, inplace=True)\n",
    "\n",
    "# preprocessed_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sameSexMarriage is true if respondant's spouse is of same sex as respondant, false otherwise (including if respondant has no spouse). Note that this is not a perfect analogue for sexuality as anyone who is not married will be marked as false and the data only includes binary sex, not gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['sameSexMarriage'] = (preprocessed_df['SEX'] == preprocessed_df['SEX_SP'])\n",
    "preprocessed_df.drop(['SEX', 'SEX_SP'], axis=1, inplace=True)\n",
    "preprocessed_df.sameSexMarriage.sum()  # Shows number of people in same sex marriages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts housing type to binary column. Values of 1-2 refer to households, while values of 3-5 refer to group quarters. Values of 0 or 6 should not be present.\n",
    "\n",
    "Note that group quarters refers to living arragements like rooming houses or military barracks, with a large number of units with individuals unrelated to the respondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(preprocessed_df.GQ.max() < 6 and preprocessed_df.GQ.min() > 0)\n",
    "\n",
    "preprocessed_df['isGroupQuarters'] = (preprocessed_df['GQ'] > 2)\n",
    "preprocessed_df.drop(['GQ'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts birthplace to binary column bornInUS. Note that this includes US outlying areas and territories: American Samoa, Guam, Puerto Rico, US Virgin Islands, and other US possessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of people born in US: {}. Number of those who were born in US outlying areas: {}'.format(\n",
    "    (preprocessed_df.BPL <= 120).sum(), ((preprocessed_df.BPL >= 100) & (preprocessed_df.BPL <= 120)).sum()))\n",
    "\n",
    "preprocessed_df['bornInUS'] = (preprocessed_df.BPL <= 120)\n",
    "preprocessed_df.drop(['BPL', 'BPLD'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Categorical Columns\n",
    "\n",
    "The next cells preprocess data that is split among multiple different categorical columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts MARST (marital status) into 3 categorical columns: isMarried, wasMarried, and neverMarried.\n",
    "\n",
    "Note that people are marked as married whether their spouse is present (MARST = 1) or absent (MARST = 2). Similarly, people are marked as wasMarried whether they are separated (MARST = 3), divorced (MARST = 4), or widowed (MARST = 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['isMarried'] = (preprocessed_df['MARST'] <= 2)\n",
    "preprocessed_df['wasMarried'] = ((preprocessed_df['MARST'] >= 3) & (preprocessed_df['MARST'] <= 5))\n",
    "preprocessed_df['neverMarried'] = (preprocessed_df['MARST'] == 6)\n",
    "preprocessed_df.drop(['MARST'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts SPEAKENG (which includes data on whether and how well the respondant speaks English) into 3 columns:\n",
    "\n",
    "1. Speaks English\n",
    "2. Speaks English well\n",
    "3. Speaks only English\n",
    "\n",
    "Note that how well the respondant speaks English is self reported by the respondant rather than being evaluated with an objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure only correct values are present in column\n",
    "assert(sorted(preprocessed_df.SPEAKENG.unique().tolist()) == [0, 1, 3, 4, 5, 6])\n",
    "\n",
    "# Create boolean columns for English speaking ability\n",
    "preprocessed_df['speaksEnglish'] = (preprocessed_df.SPEAKENG > 1)\n",
    "preprocessed_df['speaksOnlyEnglish'] = (preprocessed_df.SPEAKENG == 3)\n",
    "# Note: if respondant only speaks English, they will be marked as speaksEnglishWell\n",
    "preprocessed_df['speaksEnglishWell'] = ((preprocessed_df.SPEAKENG > 2) & (preprocessed_df.SPEAKENG < 6))\n",
    "\n",
    "# Add NaN values for respondents who didn't answer\n",
    "noResponse = (preprocessed_df.SPEAKENG == 0)\n",
    "for col in ['speaksEnglish', 'speaksOnlyEnglish', 'speaksEnglishWell']:\n",
    "    preprocessed_df.loc[noResponse, col] = np.nan\n",
    "    # preprocessed_df.loc[col, noResponse] = np.nan\n",
    "\n",
    "preprocessed_df.drop(['SPEAKENG'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellaneous Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YRMARR is the year in which respondant was last marriage. If respondent was never married, YRMARR is 0. This is converted to NaN.\n",
    "preprocessed_df.YRMARR.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Ensure there are no discrepencies in the data\n",
    "assert(preprocessed_df.YRMARR.isna() == preprocessed_df.neverMarried).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RACE and RACED dropped because race information was already encoded. Don't drop these if you want more detailed information.\n",
    "preprocessed_df.drop(['RACE', 'RACED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestry data dropped because it is not used to train the model.\n",
    "preprocessed_df.drop(['ANCESTR1', 'ANCESTR2', 'ANCESTR1D', 'ANCESTR2D'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns include languages spoken at home. This is excluded in favor of SPEAKENG, which provides less granular information.\n",
    "preprocessed_df.drop(['LANGUAGE1', 'LANGUAGED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preprocessed_df.BPL == 950).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.AGE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns with each type\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show memory usage of each column of df\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
