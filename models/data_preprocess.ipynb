{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('usa_00003.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about memory usage of df\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns with each type\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set indices\n",
    "\n",
    "The SAMPLE and SERIAL columns can uniquely identify every household, which when combined with PERNUM (a number that uniquely identifies members in each household) can uniquely identify each person. Since all data is from the same 2021 sample, SAMPLE is unnecessary. Therefore, SERIAL and PERNUM are used as indices (after being downcast to uint dtype in order to use less memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(preprocessed_df.SERIAL.min() >= 0 and preprocessed_df.PERNUM.min() >= 0)\n",
    "preprocessed_df.SERIAL = pd.to_numeric(preprocessed_df.SERIAL, downcast='unsigned')\n",
    "preprocessed_df.PERNUM = pd.to_numeric(preprocessed_df.PERNUM, downcast='unsigned')\n",
    "print(\"New datatypes: SERIAL: {}, PERNUM: {}\".format(preprocessed_df.SERIAL.dtype, preprocessed_df.PERNUM.dtype))\n",
    "preprocessed_df.set_index(['SERIAL', 'PERNUM'], inplace=True)\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnecessary columns\n",
    "\n",
    "These columns don't encode any useful data and are therefore dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All samples are from 2021 IPUMS data, so year and sample columns are unnecessary\n",
    "unnecessary_columns = ['YEAR', 'SAMPLE']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "for col in unnecessary_columns:\n",
    "    if col in preprocessed_df.columns:\n",
    "        unique = preprocessed_df[col].unique()\n",
    "        assert(len(unique) == 1)\n",
    "        print('Dropping {} column; original value: {}'.format(col, unique[0]))\n",
    "        preprocessed_df.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should print nothing after previous cell is run. If it prints anything, you can probably drop that column.\n",
    "for col in preprocessed_df.columns:\n",
    "    unique = preprocessed_df[col].unique()\n",
    "    if len(unique) == 1:\n",
    "        print(col, unique)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Quality Columns\n",
    "\n",
    "Data quality columns give information about whether the response was altered by staff. The method of this alteration is generally not specified. These columns are dropped because they are unnecessary when training the model (though they can be useful for analyzing potential discrepancies in data).\n",
    "\n",
    "Note that the original data contains 44 data quality flags, so this many columns should be dropped by the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_columns = [col for col in preprocessed_df.columns if col[0] == 'Q']\n",
    "for col in quality_columns:\n",
    "    if col[1:] not in preprocessed_df.columns:\n",
    "        print(f\"Dropping {col} but no column {col[1:]} exists. Make sure this isn't an error.\")\n",
    "\n",
    "preprocessed_df.drop(quality_columns, axis=1, inplace=True)\n",
    "print(f'Dropped {len(quality_columns)} columns')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess columns\n",
    "\n",
    "The below section will preprocess columns in order to make data easier to understand and to reduce memory usage. Each cell processes a different column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess binary columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get a list of columns with 2 unique values (which can be turned into boolean columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all columns with 2 unique values (or 3 unique values if one of them is NaN)\n",
    "for col in preprocessed_df.columns:\n",
    "    unique = preprocessed_df[col].unique()\n",
    "    if len(unique) == 2 or (len(unique) == 3 and preprocessed_df[col].isnull().values.any()):\n",
    "        print('{} ({}): {}'.format(col, preprocessed_df[col].dtype, len(unique)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, preprocess any columns that should have NaN values (this is necessary as often responses that should be NaN such as no response or N/A are instead coded as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.SCHOOL.replace(0, np.nan, inplace=True)\n",
    "preprocessed_df.CARPOOL.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of columns that will be converted to boolean columns. Each tuple contains the current column name, the name of the boolean column that it'll be converted to, and a boolean that determines whether the column will be dropped when the boolean column is created. Unless you have a good reason to keep the original column, you should drop it once the boolean column is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples containing current column name, new boolean column name, and whether to drop current column when new column created\n",
    "boolean_column_conversions = [\n",
    "    # SEX is 1 if male, 2 if female (no other options)\n",
    "    ('SEX', 'isFemale', False),\n",
    "\n",
    "    # These columns store binary race (single person can have multiple races, RACNUM stores how many races single person selected)\n",
    "    ('RACAMIND', 'isAmericanIndian', True),\n",
    "    ('RACASIAN', 'isAsian', True),\n",
    "    ('RACBLK', 'isBlack', True),\n",
    "    ('RACPACIS', 'isPacificIslander', True),\n",
    "    ('RACWHT', 'isWhite', True),\n",
    "    ('RACOTHER', 'isOtherRace', True),\n",
    "\n",
    "    # These columns store information about health insurance coverage\n",
    "\n",
    "    # Private includes HINSEMP, HINSPUR, and HINSTRI\n",
    "    ('HCOVPRIV', 'hasPrivateHealthInsurance', True),\n",
    "    # Includes current/former employers or union health insurance; or those covered by family's insurance provided by these groups\n",
    "    ('HINSEMP', 'hasEmployerHealthInsurance', True),\n",
    "    # Includes health insurance purchased directly by individual or family\n",
    "    ('HINSPUR', 'hasPurchasedPrivHealthInsurance', True),\n",
    "    # Includes TRICARE and other military health program\n",
    "    ('HINSTRI', 'hasMilitaryHealthInsurance', True),\n",
    "\n",
    "    # Public includes HINSCARE, HINSCAID, HINSVA\n",
    "    ('HCOVPUB', 'hasPublicHealthInsurance', True),\n",
    "    ('HINSCARE', 'hasMedicare', True),\n",
    "    # Includes Medicaid, Medical Assistance, or other government plans for those w/ low income or disability\n",
    "    ('HINSCAID', 'hasMedicaid', True),\n",
    "    ('HINSVA', 'hasVeteransHealthInsurance', True),  # Includes all who have ever used/enrolled for VA health care\n",
    "\n",
    "    ('HINSIHS', 'hasIndianHealthInsurance', True),  # Includes those getting insurance through Indian Health Service\n",
    "\n",
    "    # HCOVANY includes HINSEMP, HINSPUR, HINSTRI, HINSCARE, HINSCAID, HINSVA\n",
    "    # Indian Health Services insurance not included in HCOVANY (since IPUMS says IHS policies not always comprehensive)\n",
    "    ('HCOVANY', 'hasHealthInsurance', True),\n",
    "\n",
    "    # Whether respondant is currently in school\n",
    "    ('SCHOOL', 'isInSchool', True),\n",
    "\n",
    "    # Whether respondant drives alone or carpools\n",
    "    ('CARPOOL', 'carpools', True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, new_col, drop_col in boolean_column_conversions:\n",
    "    if col in preprocessed_df.columns:\n",
    "        assert(len(preprocessed_df[col].unique()) <= 3)\n",
    "        preprocessed_df[new_col] = (preprocessed_df[col] - 1).astype(\"boolean\")\n",
    "        if(preprocessed_df[col].isnull().values.any()):\n",
    "            print('Warning: {} has null values. This means {} will have null values. Make sure this is expected.'.format(col, new_col))\n",
    "            assert(preprocessed_df[new_col].isna().values.any())\n",
    "        if drop_col:\n",
    "            preprocessed_df.drop([col], axis=1, inplace=True)\n",
    "    elif new_col not in preprocessed_df.columns:\n",
    "        print('Warning: {} not in preprocessed_df so {} not generated'.format(col, new_col))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess HISPAN column into isHispanic boolean column. Dropping HISPAN and HISPAND (detailed version of HISPAN) removes information about Hispanic respondants' specific background, so don't drop these columns if you want to preserve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISPAN column is 0 if not Hispanic, nonzero if Hispanic\n",
    "\n",
    "# 9 represents unknown value. Shouldn't be present in our data.\n",
    "assert(9 not in preprocessed_df.HISPAN.values)\n",
    "\n",
    "preprocessed_df['isHispanic'] = preprocessed_df.HISPAN.astype(bool)\n",
    "\n",
    "# Drop these if you don't care about details. HISPAND is more detailed version of HISPAND\n",
    "preprocessed_df.drop(['HISPAN'], axis=1, inplace=True)\n",
    "preprocessed_df.drop(['HISPAND'], axis=1, inplace=True)\n",
    "\n",
    "preprocessed_df.isHispanic.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sameSexMarriage is true if respondant's spouse is of same sex as respondant, false otherwise (including if respondant has no spouse). Note that this is not a perfect analogue for sexuality as anyone who is not married will be marked as false and the data only includes binary sex, not gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['sameSexMarriage'] = (preprocessed_df['SEX'] == preprocessed_df['SEX_SP'])\n",
    "assert not preprocessed_df.sameSexMarriage.isnull().values.any()  # Make sure there are no null values\n",
    "preprocessed_df.drop(['SEX', 'SEX_SP'], axis=1, inplace=True)\n",
    "preprocessed_df.sameSexMarriage.sum()  # Shows number of people in same sex marriages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mixedRaceMarriage is true if the respondant's spouse is of a different race as spouse, false otherwise (including if respondant has no spouse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['mixedRaceMarriage'] = (~(preprocessed_df.RACE_SP.isnull()) & (preprocessed_df.RACE != preprocessed_df.RACE_SP))\n",
    "assert not preprocessed_df.mixedRaceMarriage.isnull().values.any()  # Make sure there are no null values\n",
    "\n",
    "# RACE and RACED dropped because race information was already encoded. Don't drop these if you want more detailed information.\n",
    "preprocessed_df.drop(['RACE', 'RACED', 'RACE_SP', 'RACED_SP'], axis=1, inplace=True)\n",
    "\n",
    "preprocessed_df.mixedRaceMarriage.sum()  # Shows number of people in same sex marriages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts housing type to binary column. Values of 1-2 refer to households, while values of 3-5 refer to group quarters. Values of 0 or 6 should not be present.\n",
    "\n",
    "Note that group quarters refers to living arragements like rooming houses or military barracks, with a large number of units with individuals unrelated to the respondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(preprocessed_df.GQ.max() < 6 and preprocessed_df.GQ.min() > 0)\n",
    "\n",
    "preprocessed_df['isGroupQuarters'] = (preprocessed_df['GQ'] > 2)\n",
    "preprocessed_df.drop(['GQ'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts birthplace to binary column bornInUS. Note that this includes US outlying areas and territories: American Samoa, Guam, Puerto Rico, US Virgin Islands, and other US possessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of people born in US: {}. Number of those who were born in US outlying areas: {}'.format(\n",
    "    (preprocessed_df.BPL <= 120).sum(), ((preprocessed_df.BPL >= 100) & (preprocessed_df.BPL <= 120)).sum()))\n",
    "\n",
    "preprocessed_df['bornInUS'] = (preprocessed_df.BPL <= 120)\n",
    "preprocessed_df.drop(['BPL', 'BPLD'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Categorical Columns\n",
    "\n",
    "The next cells preprocess data that is split among multiple different categorical columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts MARST (marital status) into 3 categorical columns: isMarried, wasMarried, and neverMarried.\n",
    "\n",
    "Note that people are marked as married whether their spouse is present (MARST = 1) or absent (MARST = 2). Similarly, people are marked as wasMarried whether they are separated (MARST = 3), divorced (MARST = 4), or widowed (MARST = 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['isMarried'] = (preprocessed_df['MARST'] <= 2)\n",
    "preprocessed_df['wasMarried'] = ((preprocessed_df['MARST'] >= 3) & (preprocessed_df['MARST'] <= 5))\n",
    "preprocessed_df['neverMarried'] = (preprocessed_df['MARST'] == 6)\n",
    "preprocessed_df.drop(['MARST'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts SPEAKENG (which includes data on whether and how well the respondant speaks English) into 3 columns:\n",
    "\n",
    "1. Speaks English\n",
    "2. Speaks English well\n",
    "3. Speaks only English\n",
    "\n",
    "Note that how well the respondant speaks English is self reported by the respondant rather than being evaluated with an objective metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure only correct values are present in column\n",
    "assert(sorted(preprocessed_df.SPEAKENG.unique().tolist()) == [0, 1, 3, 4, 5, 6])\n",
    "\n",
    "# Create boolean columns for English speaking ability\n",
    "preprocessed_df['speaksEnglish'] = (preprocessed_df.SPEAKENG > 1)\n",
    "preprocessed_df['speaksOnlyEnglish'] = (preprocessed_df.SPEAKENG == 3)\n",
    "# Note: if respondant only speaks English, they will be marked as speaksEnglishWell\n",
    "preprocessed_df['speaksEnglishWell'] = ((preprocessed_df.SPEAKENG > 2) & (preprocessed_df.SPEAKENG < 6))\n",
    "\n",
    "# Add NaN values for respondents who didn't answer\n",
    "noResponse = (preprocessed_df.SPEAKENG == 0)\n",
    "for col in ['speaksEnglish', 'speaksOnlyEnglish', 'speaksEnglishWell']:\n",
    "    preprocessed_df.loc[noResponse, col] = np.nan\n",
    "    # preprocessed_df.loc[col, noResponse] = np.nan\n",
    "\n",
    "preprocessed_df.drop(['SPEAKENG'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts EDUCD (which has data about highest educational attainment) into columns:\n",
    "1. No schooling\n",
    "2. Up to grade 4\n",
    "3. Up to grade 8\n",
    "4. Some highschool (no diploma)\n",
    "5. High school diploma\n",
    "6. Some college, no degree\n",
    "7. Associate's Degree\n",
    "8. Bachelor's Degree\n",
    "9. Bachelor's Degree plus some professional degree\n",
    "10. Master's Degree\n",
    "11. Doctoral Degree\n",
    "\n",
    "Some information about these education levels:\n",
    "* No schooling is not the same as N/A (which is marked with NaN in each column)\n",
    "* Up to grade 4 includes those whose maximum educational attainment is preschool or kindergarten (~40k and ~37k respondants respectively). This could be worth separating into another column.\n",
    "* \"Professional degree\" in column 9 refers to the fact that ~57k respondants are marked as having a professional degree beyond a bachelor's degree. Note that this professional degree is not a master's or PhD, which is labelled in separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing is marked w/ 999, so make sure that it isn't present in the data by checking bounds\n",
    "assert(preprocessed_df.EDUCD.min() == 1 and preprocessed_df.EDUCD.max() == 116)\n",
    "\n",
    "# Create boolean columns for education level\n",
    "preprocessed_df['noSchooling'] = (preprocessed_df.EDUCD == 2).astype(\"boolean\")\n",
    "preprocessed_df['maxGrade4'] = ((preprocessed_df.EDUCD <= 17) & (preprocessed_df.EDUCD >= 11)).astype(\"boolean\")\n",
    "preprocessed_df['maxGrade8'] = ((preprocessed_df.EDUCD <= 26) & (preprocessed_df.EDUCD >= 22)).astype(\"boolean\")\n",
    "preprocessed_df['maxSomeHS'] = ((preprocessed_df.EDUCD <= 61) & (preprocessed_df.EDUCD >= 30)).astype(\"boolean\")\n",
    "preprocessed_df['highSchoolDiploma'] = ((preprocessed_df.EDUCD == 63) | (preprocessed_df.EDUCD == 64)).astype(\"boolean\")\n",
    "preprocessed_df['someCollege'] = ((preprocessed_df.EDUCD == 65) | (preprocessed_df.EDUCD == 71)).astype(\"boolean\")\n",
    "preprocessed_df['associatesDegree'] = (preprocessed_df.EDUCD == 81).astype(\"boolean\")\n",
    "preprocessed_df['bachelorsDegree'] = (preprocessed_df.EDUCD == 101).astype(\"boolean\")\n",
    "preprocessed_df['mastersDegree'] = (preprocessed_df.EDUCD == 114).astype(\"boolean\")\n",
    "preprocessed_df['bachelorsPlusProfessionalDegree'] = (preprocessed_df.EDUCD == 115).astype(\"boolean\")\n",
    "preprocessed_df['doctoralDegree'] = (preprocessed_df.EDUCD == 116).astype(\"boolean\")\n",
    "\n",
    "# N/A values (which are marked with 1) will be set to NaN\n",
    "nanMask = (preprocessed_df.EDUCD == 1)\n",
    "\n",
    "# Check to make sure all respondants were covered in one of the columns (or will be set to NaN)\n",
    "assert(not (~(\n",
    "    preprocessed_df.noSchooling | preprocessed_df.maxGrade4 | preprocessed_df.maxGrade8 | preprocessed_df.maxSomeHS | preprocessed_df.highSchoolDiploma | \n",
    "    preprocessed_df.someCollege | preprocessed_df.associatesDegree | preprocessed_df.bachelorsDegree | preprocessed_df.mastersDegree | \n",
    "    preprocessed_df.bachelorsPlusProfessionalDegree | preprocessed_df.doctoralDegree | nanMask\n",
    "    )).values.any())\n",
    "\n",
    "# Set NaN values\n",
    "for col in ['noSchooling', 'maxGrade4', 'maxGrade8', 'maxSomeHS', 'highSchoolDiploma', 'someCollege', 'associatesDegree', 'bachelorsDegree', 'mastersDegree', 'bachelorsPlusProfessionalDegree', 'doctoralDegree']:\n",
    "    preprocessed_df.loc[nanMask, col] = np.nan\n",
    "    assert(preprocessed_df[col].isnull().values.sum() == nanMask.values.sum())\n",
    "\n",
    "preprocessed_df.drop(['EDUC', 'EDUCD'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['has2ndDegree'] = (preprocessed_df.DEGFIELD2 > 0).astype(\"boolean\")\n",
    "\n",
    "# Check to make sure everyone with a 2nd degree has a degree\n",
    "assert(not ((preprocessed_df.has2ndDegree) &\n",
    "    ~(preprocessed_df.bachelorsDegree | preprocessed_df.mastersDegree | preprocessed_df.bachelorsPlusProfessionalDegree | preprocessed_df.doctoralDegree).astype(\"boolean\")\n",
    "    ).values.any()\n",
    ")\n",
    "\n",
    "# 2nd degree information (beyond whether a respondant has one) is dropped\n",
    "preprocessed_df.drop(['DEGFIELD2', 'DEGFIELD2D'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 3 columns encode a person's employment status:\n",
    "1. If they are employed\n",
    "2. If they are unemployed\n",
    "3. If they are not in the labor force\n",
    "Note that if a person's employment status is N/A, each of these columns will be set to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['isEmployed'] = (preprocessed_df.EMPSTAT == 1).astype(\"boolean\")\n",
    "preprocessed_df['isUnemployed'] = (preprocessed_df.EMPSTAT == 2).astype(\"boolean\")\n",
    "preprocessed_df['isNotInLaborForce'] = (preprocessed_df.EMPSTAT == 3).astype(\"boolean\")\n",
    "\n",
    "# N/A values (which are marked with 0) will be set to NaN\n",
    "nanMask = (preprocessed_df.EMPSTAT == 0)\n",
    "print(f\"{nanMask.values.sum()} of {len(preprocessed_df)} respondants are missing employment status\")\n",
    "\n",
    "# Set NaN values\n",
    "for col in ['isEmployed', 'isUnemployed', 'isNotInLaborForce']:\n",
    "    preprocessed_df.loc[nanMask, col] = np.nan\n",
    "    assert(preprocessed_df[col].isnull().values.sum() == nanMask.values.sum())\n",
    "\n",
    "assert(preprocessed_df.isEmployed.isna().equals(preprocessed_df.isUnemployed.isna()) and \n",
    "       preprocessed_df.isEmployed.isna().equals(preprocessed_df.isNotInLaborForce.isna()))\n",
    "\n",
    "preprocessed_df.drop(['EMPSTAT', 'EMPSTATD'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 4 columns encode information about workers' class. Workers are initially separated into 3 categories: self-employed, working for wages, or N/A. Workers who work for salary are further subdivided into public or private sector workers, as well as a few (~6k) classed as unpaid family workers. Note that more granular information, such as the level of government (federal/state/local) for public sector workers or whether private sectors work at for-profit or non-profit organizations, is discarded.\n",
    "\n",
    "The columns are\n",
    "1. isSelfEmployed\n",
    "2. getsWagesPrivateSector\n",
    "3. getsWagesPublicSector\n",
    "4. isUnpaidFamilyWorker\n",
    "\n",
    "If a person responded with N/A, these columns are all marked as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(sorted(preprocessed_df.CLASSWKRD.unique().tolist()) == [0, 13, 14, 22, 23, 25, 27, 28, 29])\n",
    "\n",
    "preprocessed_df['isSelfEmployed'] = ((preprocessed_df.CLASSWKRD == 13) | (preprocessed_df.CLASSWKRD == 14)).astype(\"boolean\")\n",
    "preprocessed_df['isPrivateSector'] = ((preprocessed_df.CLASSWKRD == 22) | (preprocessed_df.CLASSWKRD == 23)).astype(\"boolean\")\n",
    "preprocessed_df['isPublicSector'] = ((preprocessed_df.CLASSWKRD >= 25) & (preprocessed_df.CLASSWKRD <= 28)).astype(\"boolean\")\n",
    "preprocessed_df['isUnpaidFamilyWorker'] = (preprocessed_df.CLASSWKRD == 29).astype(\"boolean\")\n",
    "\n",
    "# N/A values (which are marked with 0) will be set to NaN\n",
    "nanMask = (preprocessed_df.CLASSWKRD == 0)\n",
    "print(f\"{nanMask.values.sum()} of {len(preprocessed_df)} respondants have N/A for CLASSWKRD\")\n",
    "\n",
    "# Set NaN values\n",
    "for col in ['isSelfEmployed', 'isPrivateSector', 'isPublicSector', 'isUnpaidFamilyWorker']:\n",
    "    preprocessed_df.loc[nanMask, col] = np.nan\n",
    "    assert(preprocessed_df[col].isnull().values.sum() == nanMask.values.sum())\n",
    "\n",
    "assert(preprocessed_df.isSelfEmployed.isna().equals(preprocessed_df.isPrivateSector.isna()) and\n",
    "       preprocessed_df.isSelfEmployed.isna().equals(preprocessed_df.isPublicSector.isna()) and\n",
    "       preprocessed_df.isSelfEmployed.isna().equals(preprocessed_df.isUnpaidFamilyWorker.isna()))\n",
    "\n",
    "preprocessed_df.drop(['CLASSWKR', 'CLASSWKRD'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 3 columns indicate whether an individual worked in the previous year, and if not, whether they worked 1-5 years ago. N/A responses have each of these columns set to NaN. The columns are:\n",
    "1. employedLastYear\n",
    "2. employed1to5YrsAgo\n",
    "3. unemployedLast5Yrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['employedLastYear'] = (preprocessed_df.WORKEDYR == 3).astype(\"boolean\")\n",
    "preprocessed_df['employed1to5YrsAgo'] = (preprocessed_df.WORKEDYR == 2).astype(\"boolean\")\n",
    "preprocessed_df['unemployedLast5Yrs'] = (preprocessed_df.WORKEDYR == 1).astype(\"boolean\")\n",
    "\n",
    "# N/A values (which are marked with 0) will be set to NaN\n",
    "nanMask = (preprocessed_df.WORKEDYR == 0)\n",
    "print(f\"{nanMask.values.sum()} of {len(preprocessed_df)} respondants have N/A for WORKEDYR\")\n",
    "\n",
    "# Set NaN values\n",
    "for col in ['employedLastYear', 'employed1to5YrsAgo', 'unemployedLast5Yrs']:\n",
    "    preprocessed_df.loc[nanMask, col] = np.nan\n",
    "    assert(preprocessed_df[col].isnull().values.sum() == nanMask.values.sum())\n",
    "\n",
    "assert(preprocessed_df.employedLastYear.isna().equals(preprocessed_df.employed1to5YrsAgo.isna()) and\n",
    "       preprocessed_df.employedLastYear.isna().equals(preprocessed_df.unemployedLast5Yrs.isna()))\n",
    "\n",
    "preprocessed_df.drop(['WORKEDYR'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following columns indicate how an individual got to work. Note that \"N/A\" and \"other\" responses have each of these columns set to NaN. The columns are:\n",
    "1. commutePrivateVehicle\n",
    "2. commutePublicTransport\n",
    "3. commuteBikeOrWalk\n",
    "4. workFromHome\n",
    "Note that if a worker uses taxis to commute to/from work (~2k respondants), they are considered to use public transport. There are ~1.8 million N/A responses and ~16k \"other\" responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['commutePrivateVehicle'] = ((preprocessed_df.TRANWORK >= 10) & (preprocessed_df.TRANWORK <= 20)).astype(\"boolean\")\n",
    "preprocessed_df['commutePublicTransportation'] = ((preprocessed_df.TRANWORK >= 30) & (preprocessed_df.TRANWORK <= 40)).astype(\"boolean\")\n",
    "preprocessed_df['commuteBikeOrWalk'] = ((preprocessed_df.TRANWORK >= 50) & (preprocessed_df.TRANWORK <= 60)).astype(\"boolean\")\n",
    "preprocessed_df['workFromHome'] = (preprocessed_df.TRANWORK == 80).astype(\"boolean\")\n",
    "\n",
    "# N/A values (which are marked with 0) and other values (which are marked with 70) will be set to NaN\n",
    "nanMask = (preprocessed_df.TRANWORK == 0) | (preprocessed_df.TRANWORK == 70)\n",
    "print(f\"{nanMask.values.sum()} of {len(preprocessed_df)} respondants have N/A or other for TRANWORK\")\n",
    "\n",
    "# Set NaN values\n",
    "for col in ['commutePrivateVehicle', 'commutePublicTransportation', 'commuteBikeOrWalk', 'workFromHome']:\n",
    "    preprocessed_df.loc[nanMask, col] = np.nan\n",
    "    assert(preprocessed_df[col].isnull().values.sum() == nanMask.values.sum())\n",
    "\n",
    "assert(preprocessed_df.commutePrivateVehicle.isna().equals(preprocessed_df.commutePublicTransportation.isna()) and\n",
    "       preprocessed_df.commutePrivateVehicle.isna().equals(preprocessed_df.commuteBikeOrWalk.isna()) and\n",
    "       preprocessed_df.commutePrivateVehicle.isna().equals(preprocessed_df.workFromHome.isna()))\n",
    "\n",
    "preprocessed_df.drop(['TRANWORK'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following 2 columns encode whether someone is attending public or private school. Note that each row with isInSchool=True will be marked as either in public or private. Those not in school will be marked as false, while those for whom data is unavailable will have NaN values in these 2 columns (as well as in isInSchool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['attendingPublicSchool'] = (preprocessed_df.SCHLTYPE == 2).astype(\"boolean\")\n",
    "preprocessed_df['attendingPrivateSchool'] = (preprocessed_df.SCHLTYPE == 3).astype(\"boolean\")\n",
    "\n",
    "# N/A values (which are marked with 0) will be set to NaN\n",
    "nanMask = (preprocessed_df.SCHLTYPE == 0)\n",
    "\n",
    "# Check to make sure values match up with isInSchool column\n",
    "assert(nanMask.equals(preprocessed_df.isInSchool.isnull()))\n",
    "assert(preprocessed_df.isInSchool.fillna(False).equals(preprocessed_df.attendingPublicSchool | preprocessed_df.attendingPrivateSchool))\n",
    "\n",
    "# Set NaN values\n",
    "for col in ['attendingPublicSchool', 'attendingPrivateSchool']:\n",
    "    preprocessed_df.loc[nanMask, col] = np.nan\n",
    "    assert(preprocessed_df[col].isnull().values.sum() == nanMask.values.sum())\n",
    "\n",
    "# Check to make sure NaN values match up with isInSchool column\n",
    "assert(preprocessed_df.isInSchool.isnull().equals(preprocessed_df.attendingPublicSchool.isnull()))\n",
    "assert(preprocessed_df.isInSchool.isnull().equals(preprocessed_df.attendingPrivateSchool.isnull()))\n",
    "\n",
    "preprocessed_df.drop(['SCHLTYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Miscellaneous Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YRMARR is the year in which respondant had their most recent marriage. If respondent was never married, YRMARR is 0. This is converted to NaN.\n",
    "preprocessed_df.YRMARR.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Ensure there are no discrepencies in the data\n",
    "assert(preprocessed_df.YRMARR.isna() == preprocessed_df.neverMarried).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YRNATUR is the year in which respondant was naturalized as US citizen. If respondent was never naturalized, YRNATUR is 9999. This is converted to NaN.\n",
    "preprocessed_df.YRNATUR.replace(9999, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ancestry data dropped because it is not used to train the model.\n",
    "preprocessed_df.drop(['ANCESTR1', 'ANCESTR2', 'ANCESTR1D', 'ANCESTR2D'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Citizenship data and number of years in the US is dropped as it is unavailable for most (~2.8 million) of the respondants\n",
    "preprocessed_df.drop(['CITIZEN', 'YRSUSA1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns include languages spoken at home. This is excluded in favor of SPEAKENG, which provides less granular information.\n",
    "preprocessed_df.drop(['LANGUAGE', 'LANGUAGED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This information is already extracted from the EMPSTAT column\n",
    "preprocessed_df.drop(['LABFORCE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WKSWORK1 = 0 represents N/A. This is converted to NaN.\n",
    "preprocessed_df.WKSWORK1.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UHRSWORK = 0 represents N/A. This is converted to NaN.\n",
    "preprocessed_df.UHRSWORK.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WKSWORK1 is the number of weeks worked in the last year. WKSWORK2, which is a less granular version of WKSWORK1, is dropped.\n",
    "preprocessed_df.drop(['WKSWORK2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The industry in which an individual works is dropped. The respondant's occupation is more relevant.\n",
    "preprocessed_df.drop(['IND'], axis=1, inplace=True)\n",
    "# The 2010 version of occupation (OCC2010) is used, so OCC is dropped\n",
    "preprocessed_df.drop(['OCC'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop CBSERIAL (original census bureau serial number for household) in favor of SERIAL\n",
    "preprocessed_df.drop(['CBSERIAL'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no values are missing (999998) or N/A (999999)\n",
    "assert(preprocessed_df.INCWAGE_CPIU_2010.max() < 999998)\n",
    "assert(preprocessed_df.INCWAGE_CPIU_2010.min() >= 0)\n",
    "\n",
    "# Drop INCWAGE in favor of INCWAGE_CPIU_2010 (which is adjusted for inflation to 2010 dollars)\n",
    "preprocessed_df.drop(['INCWAGE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop information about total income (includes income from all sources, not just salary) and family income\n",
    "preprocessed_df.drop(['INCTOT', 'FTOTINC'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop information about how far above/below poverty line income is (this would let model cheat by learning what the poverty line is)\n",
    "preprocessed_df.drop(['POVERTY'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop earnings and education scores (calculated by IPUMS - ideally our model shouldn't need these)\n",
    "preprocessed_df.drop(['ERSCOR90', 'EDSCOR90'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop information about number of riders in transportation used to get to work\n",
    "preprocessed_df.drop(['RIDERS'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(preprocessed_df.TRANTIME.min() == 0)\n",
    "\n",
    "# TRANTIME = 0 represents N/A. This is converted to NaN.\n",
    "preprocessed_df.TRANTIME.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(preprocessed_df.columns)} columns in total\")\n",
    "preprocessed_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of columns with each type\n",
    "preprocessed_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show memory usage of each column of df\n",
    "preprocessed_df.memory_usage()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save preprocessed data\n",
    "\n",
    "At this point, all of the simple preprocessing is complete. Preprocessing that will create a lot more categorical columns, such as preprocessing of DEGFIELD, OCC2010, and PWSTATE2 is done in a separate notebook. This ensures the file created by this notebook will not have too many columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "\n",
    "# preprocessed_df.reset_index(inplace=True)\n",
    "preprocessed_df.to_csv(\n",
    "    \"init_preprocessed_data.csv.gz\",\n",
    "    sep='|',\n",
    "    header=True,\n",
    "    index=True,\n",
    "    quoting=csv.QUOTE_ALL,\n",
    "    compression='gzip',\n",
    "    quotechar='\"',\n",
    "    doublequote=True,\n",
    "    lineterminator='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.to_csv(\n",
    "    \"init_preprocessed_data.csv\",\n",
    "    header=True,\n",
    "    index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.reset_index().to_csv(\n",
    "    \"init_preprocessed_data_without_index.csv\",\n",
    "    header=True,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
