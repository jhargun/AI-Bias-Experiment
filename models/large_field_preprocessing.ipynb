{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\School\\University\\3A\\CS_492\\AI-Bias-Experiment\\models\\training\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (37,47,48,49,50,51,52,53,54,55,56,57,58,59,60,76,77) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3252599"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('init_preprocessed_data_without_index.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SERIAL', 'PERNUM', 'HHWT', 'CLUSTER', 'STRATA', 'PERWT', 'AGE',\n",
       "       'YRMARR', 'YRNATUR', 'RACNUM', 'DEGFIELD', 'DEGFIELDD', 'OCC2010',\n",
       "       'WKSWORK1', 'UHRSWORK', 'INCWAGE_CPIU_2010', 'PWSTATE2', 'PWCOUNTY',\n",
       "       'PWTYPE', 'TRANTIME', 'isFemale', 'isAmericanIndian', 'isAsian',\n",
       "       'isBlack', 'isPacificIslander', 'isWhite', 'isOtherRace',\n",
       "       'hasPrivateHealthInsurance', 'hasEmployerHealthInsurance',\n",
       "       'hasPurchasedPrivHealthInsurance', 'hasMilitaryHealthInsurance',\n",
       "       'hasPublicHealthInsurance', 'hasMedicare', 'hasMedicaid',\n",
       "       'hasVeteransHealthInsurance', 'hasIndianHealthInsurance',\n",
       "       'hasHealthInsurance', 'isInSchool', 'carpools', 'isHispanic',\n",
       "       'sameSexMarriage', 'mixedRaceMarriage', 'isGroupQuarters', 'bornInUS',\n",
       "       'isMarried', 'wasMarried', 'neverMarried', 'speaksEnglish',\n",
       "       'speaksOnlyEnglish', 'speaksEnglishWell', 'noSchooling', 'maxGrade4',\n",
       "       'maxGrade8', 'maxSomeHS', 'highSchoolDiploma', 'someCollege',\n",
       "       'associatesDegree', 'bachelorsDegree', 'mastersDegree',\n",
       "       'bachelorsPlusProfessionalDegree', 'doctoralDegree', 'has2ndDegree',\n",
       "       'isEmployed', 'isUnemployed', 'isNotInLaborForce', 'isSelfEmployed',\n",
       "       'isPrivateSector', 'isPublicSector', 'isUnpaidFamilyWorker',\n",
       "       'employedLastYear', 'employed1to5YrsAgo', 'unemployedLast5Yrs',\n",
       "       'commutePrivateVehicle', 'commutePublicTransportation',\n",
       "       'commuteBikeOrWalk', 'workFromHome', 'attendingPublicSchool',\n",
       "       'attendingPrivateSchool'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>YRMARR</th>\n",
       "      <th>YRNATUR</th>\n",
       "      <th>RACNUM</th>\n",
       "      <th>...</th>\n",
       "      <th>isUnpaidFamilyWorker</th>\n",
       "      <th>employedLastYear</th>\n",
       "      <th>employed1to5YrsAgo</th>\n",
       "      <th>unemployedLast5Yrs</th>\n",
       "      <th>commutePrivateVehicle</th>\n",
       "      <th>commutePublicTransportation</th>\n",
       "      <th>commuteBikeOrWalk</th>\n",
       "      <th>workFromHome</th>\n",
       "      <th>attendingPublicSchool</th>\n",
       "      <th>attendingPrivateSchool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2021000000011</td>\n",
       "      <td>80001</td>\n",
       "      <td>13.0</td>\n",
       "      <td>85</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2021000000021</td>\n",
       "      <td>80001</td>\n",
       "      <td>51.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2021000000031</td>\n",
       "      <td>120001</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2021000000041</td>\n",
       "      <td>170001</td>\n",
       "      <td>61.0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2021000000051</td>\n",
       "      <td>50001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SERIAL  PERNUM  HHWT        CLUSTER  STRATA  PERWT  AGE  YRMARR  YRNATUR  \\\n",
       "0       1       1  13.0  2021000000011   80001   13.0   85  1971.0      NaN   \n",
       "1       2       1  51.0  2021000000021   80001   51.0   67  1970.0      NaN   \n",
       "2       3       1  17.0  2021000000031  120001   17.0   74  1991.0      NaN   \n",
       "3       4       1  61.0  2021000000041  170001   61.0   16     NaN      NaN   \n",
       "4       5       1  15.0  2021000000051   50001   15.0   83  2016.0      NaN   \n",
       "\n",
       "   RACNUM  ...  isUnpaidFamilyWorker  employedLastYear  employed1to5YrsAgo  \\\n",
       "0       1  ...                   NaN             False               False   \n",
       "1       1  ...                   NaN             False               False   \n",
       "2       1  ...                   NaN             False               False   \n",
       "3       1  ...                   NaN             False               False   \n",
       "4       1  ...                   NaN             False               False   \n",
       "\n",
       "   unemployedLast5Yrs  commutePrivateVehicle  commutePublicTransportation  \\\n",
       "0                True                    NaN                          NaN   \n",
       "1                True                    NaN                          NaN   \n",
       "2                True                    NaN                          NaN   \n",
       "3                True                    NaN                          NaN   \n",
       "4                True                    NaN                          NaN   \n",
       "\n",
       "   commuteBikeOrWalk  workFromHome  attendingPublicSchool  \\\n",
       "0                NaN           NaN                  False   \n",
       "1                NaN           NaN                  False   \n",
       "2                NaN           NaN                  False   \n",
       "3                NaN           NaN                  False   \n",
       "4                NaN           NaN                  False   \n",
       "\n",
       "   attendingPrivateSchool  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                    True  \n",
       "4                   False  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create state fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1803778 (55.46%) of the rows have no state\n"
     ]
    }
   ],
   "source": [
    "num_nostate = (df.PWSTATE2 == 0).values.sum()\n",
    "original_len = len(df)\n",
    "print(f\"{num_nostate} ({num_nostate/original_len:.2%}) of the rows have no state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1803778 rows with no state. 1448821 rows remain.\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with no state\n",
    "df = df[df.PWSTATE2 != 0]\n",
    "assert(len(df) == original_len - num_nostate)\n",
    "print(f\"Removed {num_nostate} rows with no state. {len(df)} rows remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column isEmployed since it has only one value: True\n",
      "Dropping column isUnemployed since it has only one value: False\n",
      "Dropping column isNotInLaborForce since it has only one value: False\n",
      "Dropping column employedLastYear since it has only one value: True\n",
      "Dropping column employed1to5YrsAgo since it has only one value: False\n",
      "Dropping column unemployedLast5Yrs since it has only one value: False\n",
      "Dropped 6 columns. 72 columns remain.\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are now unnecessary\n",
    "\n",
    "origNumCols = len(df.columns)\n",
    "droppedCols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    unique = df[col].unique()\n",
    "    if(len(unique) == 1):\n",
    "        print(f\"Dropping column {col} since it has only one value: {unique[0]}\")\n",
    "        droppedCols.append(col)\n",
    "    elif(len(unique) == 2 and df[col].isna().values.any()):\n",
    "        print(f\"Warning: Column {col} has two values but you may still want to drop it: {unique[0]} and {unique[1]}\")\n",
    "\n",
    "df.drop(droppedCols, axis=1, inplace=True)\n",
    "assert(len(df.columns) == origNumCols - len(droppedCols))\n",
    "print(f\"Dropped {len(droppedCols)} columns. {len(df.columns)} columns remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(open('ipums_fields/stateField.json')) as f:\n",
    "    state_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure each degree field is in the mapping\n",
    "stateKeys = sorted([int(k) for k in state_mapping.keys() if int(k) != 0])\n",
    "# Note that stateKeys doesn't include foreign countries\n",
    "assert(sorted([val for val in df.PWSTATE2.unique().tolist() if val <= stateKeys[-1]]) == stateKeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 53 columns\n"
     ]
    }
   ],
   "source": [
    "df[\"worksOutsideUS\"] = (df.PWSTATE2 > stateKeys[-1])\n",
    "cols_created = 1\n",
    "for (key, value) in state_mapping.items():\n",
    "    # Skip N/A column (may want to fill this with NaN later)\n",
    "    if value == 'N/A':\n",
    "        continue\n",
    "\n",
    "    stateName = value.replace(' ', '_')\n",
    "    df[f\"worksIn_{stateName}\"] = (df.PWSTATE2 == int(key))\n",
    "    cols_created += 1\n",
    "\n",
    "print(f\"Created {cols_created} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['PWSTATE2', 'PWCOUNTY', 'PWTYPE'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create degree fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(open('ipums_fields/degField.json')) as f:\n",
    "    deg_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure each degree field is in the mapping\n",
    "assert(sorted(df.DEGFIELD.unique().tolist()) == sorted([int(k) for k in deg_mapping.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 37 columns\n"
     ]
    }
   ],
   "source": [
    "cols_created = 0\n",
    "for (key, value) in deg_mapping.items():\n",
    "    # Skip N/A column (may want to fill this with NaN later)\n",
    "    if value == 'N/A':\n",
    "        continue\n",
    "\n",
    "    degName = value.replace(' ', '_').replace(',', '')\n",
    "    df[f\"hasDegree_{degName}\"] = (df.DEGFIELD == int(key))\n",
    "    cols_created += 1\n",
    "\n",
    "print(f\"Created {cols_created} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['DEGFIELD', 'DEGFIELDD'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create occupation fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(open('ipums_fields/occupation2010.json')) as f:\n",
    "    occ_mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No examples of job code 9920 (occupation Unemployed, with No Work Experience in the Last 5 Years or Earlier or Never Worked)\n"
     ]
    }
   ],
   "source": [
    "# Make sure each degree field is in the mapping\n",
    "sortedOcc = sorted([int(k) for k in occ_mapping.keys()])\n",
    "uniqueCodes = df.OCC2010.unique().tolist()\n",
    "removedKeys = []\n",
    "\n",
    "for jobCode in uniqueCodes:\n",
    "    assert(jobCode in sortedOcc)\n",
    "\n",
    "for jobCode in sortedOcc:\n",
    "    if jobCode not in uniqueCodes:\n",
    "        removedKeys.append(jobCode)\n",
    "        print(f\"No examples of job code {jobCode} (occupation {occ_mapping[str(jobCode)]})\")\n",
    "# assert(sorted(df.OCC2010.unique().tolist()) == )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\School\\University\\3A\\CS_492\\AI-Bias-Experiment\\models\\training\\venv\\lib\\site-packages\\ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 427 columns\n"
     ]
    }
   ],
   "source": [
    "cols_created = 0\n",
    "for (key, value) in occ_mapping.items():\n",
    "    # Skip N/A column (may want to fill this with NaN later)\n",
    "    if value == 'N/A':\n",
    "        continue\n",
    "    \n",
    "    # Skip occupations that were removed\n",
    "    if key in removedKeys:\n",
    "        continue\n",
    "\n",
    "    occName = value.replace(' ', '_').replace(',', '')\n",
    "    df[f\"occupation_{occName}\"] = (df.OCC2010 == int(key))\n",
    "    cols_created += 1\n",
    "\n",
    "print(f\"Created {cols_created} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 427 columns\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created {cols_created} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['OCC2010'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().to_csv('large_field_preprocessed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
