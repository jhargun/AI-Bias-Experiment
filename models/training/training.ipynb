{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Change input size\n",
    "        self.input = nn.Linear(573, 128)\n",
    "        self.hidden1 = nn.Linear(128, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.hidden3 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = self.output(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables Definintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = int(time.time())\n",
    "useCUDA = True\n",
    "dataPath = \"../large_field_preprocessed_data.csv\"\n",
    "epochs = 100\n",
    "batchSize = 32\n",
    "modelPath = f\"models/{t}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if not useCUDA:\n",
    "\tdevice = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropColumns = [\n",
    "    \"SERIAL\",\n",
    "    \"PERNUM\",\n",
    "    \"HHWT\",\n",
    "    \"CLUSTER\",\n",
    "    \"STRATA\",\n",
    "    \"PERWT\",\n",
    "    \"YRMARR\",\n",
    "    \"YRNATUR\",\n",
    "    \"RACNUM\",\n",
    "    \"index\",\n",
    "    \n",
    "]\n",
    "\n",
    "data = data.drop(columns=dropColumns)\n",
    "\n",
    "for column in data.columns:\n",
    "\tdata[column].fillna(False, inplace=True)\n",
    " \n",
    "data = data.drop(data[(data['INCWAGE_CPIU_2010'] == 0)].index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1369570, 574)\n",
      "Index(['AGE', 'WKSWORK1', 'UHRSWORK', 'INCWAGE_CPIU_2010', 'TRANTIME',\n",
      "       'isFemale', 'isAmericanIndian', 'isAsian', 'isBlack',\n",
      "       'isPacificIslander',\n",
      "       ...\n",
      "       'occupation_Machine_Feeders_and_Offbearers',\n",
      "       'occupation_Packers_and_Packagers_Hand',\n",
      "       'occupation_Pumping_Station_Operators',\n",
      "       'occupation_Refuse_and_Recyclable_Material_Collectors',\n",
      "       'occupation_Material_moving_workers_nec',\n",
      "       'occupation_Military_Officer_Special_and_Tactical_Operations_Leaders',\n",
      "       'occupation_First-Line_Enlisted_Military_Supervisors',\n",
      "       'occupation_Military_Enlisted_Tactical_Operations_and_Air/Weapons_Specialists_and_Crew_Members',\n",
      "       'occupation_Military_Rank_Not_Specified',\n",
      "       'occupation_Unemployed_with_No_Work_Experience_in_the_Last_5_Years_or_Earlier_or_Never_Worked'],\n",
      "      dtype='object', length=574)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "\n",
    "# # dump columns into json file\n",
    "# with open(\"columns.json\", \"w\") as f:\n",
    "# \tjson.dump(list(data.columns), f)\n",
    " \n",
    "# with open(\"heads.json\", \"w\") as f:\n",
    "# \tjson.dump(list(data.head(1).values[0]), f)\n",
    "\n",
    "# set to float32\n",
    "data['INCWAGE_CPIU_2010'] = data['INCWAGE_CPIU_2010'].astype(np.float32)\n",
    "\n",
    "for column in data.columns:\n",
    "\tif column == \"INCWAGE_CPIU_2010\":\n",
    "\t\tcontinue\n",
    "\tdata[column] = data[column].astype(np.float32)\n",
    "\n",
    "# print(data.head(1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTensor = torch.tensor(data.drop(columns=['INCWAGE_CPIU_2010']).values, dtype=torch.float32)\n",
    "yTensor = torch.tensor(data['INCWAGE_CPIU_2010'].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1369570, 573])\n",
      "torch.Size([1369570])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(xTensor.shape)\n",
    "print(yTensor.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "\n",
    "xTensor = xTensor.to(device)\n",
    "yTensor = yTensor.to(device)\n",
    "\n",
    "print(device)\n",
    "\n",
    "# create dataset\n",
    "dataset = TensorDataset(xTensor, yTensor)\n",
    "\n",
    "trainset, valset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.9), int(len(dataset)*0.1)])\n",
    "\n",
    "# create dataloader for both train and test\n",
    "trainLoader = DataLoader(trainset, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Started\n",
      "[1,  1000] loss: 5767753158.784\n",
      "[1,  2000] loss: 5624029776.000\n",
      "[1,  3000] loss: 5256510432.512\n",
      "[1,  4000] loss: 4383660381.184\n",
      "[1,  5000] loss: 3597965256.512\n",
      "[1,  6000] loss: 3106972671.424\n",
      "[1,  7000] loss: 3094358615.936\n",
      "[1,  8000] loss: 3044637310.784\n",
      "[1,  9000] loss: 3090047224.896\n",
      "[2,  1000] loss: 3003518104.576\n",
      "[2,  2000] loss: 2985892675.392\n",
      "[2,  3000] loss: 2962963092.032\n",
      "[2,  4000] loss: 2964452622.720\n",
      "[2,  5000] loss: 3019813149.952\n",
      "[2,  6000] loss: 2909359171.136\n",
      "[2,  7000] loss: 2944000918.144\n",
      "[2,  8000] loss: 2916749591.936\n",
      "[2,  9000] loss: 2892786915.008\n",
      "[3,  1000] loss: 2849717237.056\n",
      "[3,  2000] loss: 2855673243.776\n",
      "[3,  3000] loss: 2833132499.328\n",
      "[3,  4000] loss: 2814346601.728\n",
      "[3,  5000] loss: 2920898713.280\n",
      "[3,  6000] loss: 2760360731.904\n",
      "[3,  7000] loss: 2797274491.968\n",
      "[3,  8000] loss: 2878870439.936\n",
      "[3,  9000] loss: 2795007251.776\n",
      "[4,  1000] loss: 2749597036.416\n",
      "[4,  2000] loss: 2774491621.824\n",
      "[4,  3000] loss: 2757092952.960\n",
      "[4,  4000] loss: 2652367242.880\n",
      "[4,  5000] loss: 2668217309.888\n",
      "[4,  6000] loss: 2657776345.728\n",
      "[4,  7000] loss: 2564847181.248\n",
      "[4,  8000] loss: 2592918984.000\n",
      "[4,  9000] loss: 2589508880.448\n",
      "[5,  1000] loss: 2606897672.288\n",
      "[5,  2000] loss: 2535089843.520\n",
      "[5,  3000] loss: 2544323465.056\n",
      "[5,  4000] loss: 2478990495.680\n",
      "[5,  5000] loss: 2411690763.776\n",
      "[5,  6000] loss: 2361497923.424\n",
      "[5,  7000] loss: 2355322802.496\n",
      "[5,  8000] loss: 2457018753.280\n",
      "[5,  9000] loss: 2381085336.896\n",
      "[6,  1000] loss: 2365925332.128\n",
      "[6,  2000] loss: 2382621391.104\n",
      "[6,  3000] loss: 2324419173.792\n",
      "[6,  4000] loss: 2190787638.624\n",
      "[6,  5000] loss: 2252167963.680\n",
      "[6,  6000] loss: 2305223204.288\n",
      "[6,  7000] loss: 2263620913.920\n",
      "[6,  8000] loss: 2251073636.064\n",
      "[6,  9000] loss: 2277846224.256\n",
      "[7,  1000] loss: 2244811537.472\n",
      "[7,  2000] loss: 2203137985.312\n",
      "[7,  3000] loss: 2147595178.848\n",
      "[7,  4000] loss: 2293272476.128\n",
      "[7,  5000] loss: 2159297744.896\n",
      "[7,  6000] loss: 2261359460.160\n",
      "[7,  7000] loss: 2155590810.624\n",
      "[7,  8000] loss: 2165339411.488\n",
      "[7,  9000] loss: 2186529015.520\n",
      "[8,  1000] loss: 2117943500.256\n",
      "[8,  2000] loss: 2191403383.968\n",
      "[8,  3000] loss: 2204304245.184\n",
      "[8,  4000] loss: 2125240393.664\n",
      "[8,  5000] loss: 2150117979.680\n",
      "[8,  6000] loss: 2155954199.104\n",
      "[8,  7000] loss: 2121130268.992\n",
      "[8,  8000] loss: 2136413820.064\n",
      "[8,  9000] loss: 2084618368.800\n",
      "[9,  1000] loss: 2068294323.040\n",
      "[9,  2000] loss: 2102381481.856\n",
      "[9,  3000] loss: 2070994624.192\n",
      "[9,  4000] loss: 2067017961.024\n",
      "[9,  5000] loss: 2076048046.336\n",
      "[9,  6000] loss: 2113045586.976\n",
      "[9,  7000] loss: 2153883044.224\n",
      "[9,  8000] loss: 2066282114.336\n",
      "[9,  9000] loss: 2061240857.728\n",
      "[10,  1000] loss: 2080743740.160\n",
      "[10,  2000] loss: 2050996917.280\n",
      "[10,  3000] loss: 2036185396.256\n",
      "[10,  4000] loss: 2010783395.744\n",
      "[10,  5000] loss: 2040217814.816\n",
      "[10,  6000] loss: 2115150250.016\n",
      "[10,  7000] loss: 2044796108.896\n",
      "[10,  8000] loss: 1956108892.000\n",
      "[10,  9000] loss: 2037391033.760\n",
      "[11,  1000] loss: 2021543513.376\n",
      "[11,  2000] loss: 2028401963.328\n",
      "[11,  3000] loss: 1997371388.160\n",
      "[11,  4000] loss: 1986080257.376\n",
      "[11,  5000] loss: 2004297471.072\n",
      "[11,  6000] loss: 2031918481.280\n",
      "[11,  7000] loss: 2042269416.608\n",
      "[11,  8000] loss: 2015307370.112\n",
      "[11,  9000] loss: 2013571871.264\n",
      "[12,  1000] loss: 1989627728.448\n",
      "[12,  2000] loss: 1979562520.672\n",
      "[12,  3000] loss: 2036077500.160\n",
      "[12,  4000] loss: 2017252051.296\n",
      "[12,  5000] loss: 2025127242.464\n",
      "[12,  6000] loss: 1947565172.960\n",
      "[12,  7000] loss: 2019551162.496\n",
      "[12,  8000] loss: 1932242547.264\n",
      "[12,  9000] loss: 1968438814.144\n",
      "[13,  1000] loss: 1926524849.280\n",
      "[13,  2000] loss: 1923338981.696\n",
      "[13,  3000] loss: 1995718067.328\n",
      "[13,  4000] loss: 1989027368.032\n",
      "[13,  5000] loss: 1971052153.312\n",
      "[13,  6000] loss: 1975331931.840\n",
      "[13,  7000] loss: 1959396287.712\n",
      "[13,  8000] loss: 1983325112.704\n",
      "[13,  9000] loss: 1962707669.952\n",
      "[14,  1000] loss: 1979679681.568\n",
      "[14,  2000] loss: 1933840831.680\n",
      "[14,  3000] loss: 1941917227.552\n",
      "[14,  4000] loss: 1937774656.672\n",
      "[14,  5000] loss: 2043272421.472\n",
      "[14,  6000] loss: 1909232222.656\n",
      "[14,  7000] loss: 1909879000.224\n",
      "[14,  8000] loss: 1932155883.808\n",
      "[14,  9000] loss: 1941237711.360\n",
      "[15,  1000] loss: 1919217554.880\n",
      "[15,  2000] loss: 1898883284.800\n",
      "[15,  3000] loss: 1957058286.112\n",
      "[15,  4000] loss: 1939143509.632\n",
      "[15,  5000] loss: 1943262692.416\n",
      "[15,  6000] loss: 1925796169.952\n",
      "[15,  7000] loss: 1978291814.976\n",
      "[15,  8000] loss: 1896197411.520\n",
      "[15,  9000] loss: 1944784321.888\n",
      "[16,  1000] loss: 1933786366.368\n",
      "[16,  2000] loss: 1942047186.624\n",
      "[16,  3000] loss: 1881595742.432\n",
      "[16,  4000] loss: 1898684075.296\n",
      "[16,  5000] loss: 1974165584.416\n",
      "[16,  6000] loss: 1939933078.912\n",
      "[16,  7000] loss: 1895626183.808\n",
      "[16,  8000] loss: 1880420678.272\n",
      "[16,  9000] loss: 1895672428.000\n",
      "[17,  1000] loss: 1922221955.808\n",
      "[17,  2000] loss: 1950507270.080\n",
      "[17,  3000] loss: 1930309372.672\n",
      "[17,  4000] loss: 1898386014.560\n",
      "[17,  5000] loss: 1896390702.656\n",
      "[17,  6000] loss: 1916888538.080\n",
      "[17,  7000] loss: 1847652480.512\n",
      "[17,  8000] loss: 1910782090.720\n",
      "[17,  9000] loss: 1909057197.216\n",
      "[18,  1000] loss: 1875652339.904\n",
      "[18,  2000] loss: 1888342292.064\n",
      "[18,  3000] loss: 1910998252.128\n",
      "[18,  4000] loss: 1882080346.752\n",
      "[18,  5000] loss: 1954052766.944\n",
      "[18,  6000] loss: 1926096486.656\n",
      "[18,  7000] loss: 1887540689.568\n",
      "[18,  8000] loss: 1942875416.096\n",
      "[18,  9000] loss: 1838691126.784\n",
      "[19,  1000] loss: 1866099527.456\n",
      "[19,  2000] loss: 1910589867.072\n",
      "[19,  3000] loss: 1935395731.360\n",
      "[19,  4000] loss: 1906447157.120\n",
      "[19,  5000] loss: 1904387055.040\n",
      "[19,  6000] loss: 1893562891.840\n",
      "[19,  7000] loss: 1902883224.000\n",
      "[19,  8000] loss: 1837192759.552\n",
      "[19,  9000] loss: 1854004232.064\n",
      "[20,  1000] loss: 1885431855.712\n",
      "[20,  2000] loss: 1915508959.392\n",
      "[20,  3000] loss: 1919909087.104\n",
      "[20,  4000] loss: 1852438491.840\n",
      "[20,  5000] loss: 1840376056.896\n",
      "[20,  6000] loss: 1909302541.120\n",
      "[20,  7000] loss: 1879753419.648\n",
      "[20,  8000] loss: 1871866023.488\n",
      "[20,  9000] loss: 1871613277.792\n",
      "[21,  1000] loss: 1897434627.104\n",
      "[21,  2000] loss: 1860918563.488\n",
      "[21,  3000] loss: 1836645547.552\n",
      "[21,  4000] loss: 1893188246.816\n",
      "[21,  5000] loss: 1863914657.920\n",
      "[21,  6000] loss: 1885970392.704\n",
      "[21,  7000] loss: 1874324995.424\n",
      "[21,  8000] loss: 1897492559.424\n",
      "[21,  9000] loss: 1876868149.248\n",
      "[22,  1000] loss: 1884802830.560\n",
      "[22,  2000] loss: 1867481320.480\n",
      "[22,  3000] loss: 1847134210.784\n",
      "[22,  4000] loss: 1845346808.192\n",
      "[22,  5000] loss: 1830803609.312\n",
      "[22,  6000] loss: 1904435380.064\n",
      "[22,  7000] loss: 1879960373.392\n",
      "[22,  8000] loss: 1843491223.008\n",
      "[22,  9000] loss: 1905541297.344\n",
      "[23,  1000] loss: 1857576817.920\n",
      "[23,  2000] loss: 1876158175.136\n",
      "[23,  3000] loss: 1854203868.352\n",
      "[23,  4000] loss: 1874275294.176\n",
      "[23,  5000] loss: 1888475697.216\n",
      "[23,  6000] loss: 1813031538.816\n",
      "[23,  7000] loss: 1864789966.336\n",
      "[23,  8000] loss: 1893673640.320\n",
      "[23,  9000] loss: 1842408473.056\n",
      "[24,  1000] loss: 1827077023.936\n",
      "[24,  2000] loss: 1844846519.200\n",
      "[24,  3000] loss: 1877181309.632\n",
      "[24,  4000] loss: 1870262271.008\n",
      "[24,  5000] loss: 1864144302.048\n",
      "[24,  6000] loss: 1880780724.384\n",
      "[24,  7000] loss: 1845326307.552\n",
      "[24,  8000] loss: 1841627117.152\n",
      "[24,  9000] loss: 1869797577.344\n",
      "[25,  1000] loss: 1866307812.480\n",
      "[25,  2000] loss: 1844468876.800\n",
      "[25,  3000] loss: 1833356422.528\n",
      "[25,  4000] loss: 1865159275.936\n",
      "[25,  5000] loss: 1890643866.144\n",
      "[25,  6000] loss: 1895775377.088\n",
      "[25,  7000] loss: 1851774307.168\n",
      "[25,  8000] loss: 1817139149.920\n",
      "[25,  9000] loss: 1825723323.520\n",
      "[26,  1000] loss: 1863229087.520\n",
      "[26,  2000] loss: 1842202187.552\n",
      "[26,  3000] loss: 1855091923.488\n",
      "[26,  4000] loss: 1881908743.616\n",
      "[26,  5000] loss: 1847652550.016\n",
      "[26,  6000] loss: 1886434426.016\n",
      "[26,  7000] loss: 1808214655.872\n",
      "[26,  8000] loss: 1851950668.736\n",
      "[26,  9000] loss: 1854272564.832\n",
      "[27,  1000] loss: 1859808191.968\n",
      "[27,  2000] loss: 1817340952.064\n",
      "[27,  3000] loss: 1868416749.216\n",
      "[27,  4000] loss: 1807759896.160\n",
      "[27,  5000] loss: 1847188713.248\n",
      "[27,  6000] loss: 1872318058.496\n",
      "[27,  7000] loss: 1856714300.768\n",
      "[27,  8000] loss: 1845162401.216\n",
      "[27,  9000] loss: 1858343514.272\n",
      "[28,  1000] loss: 1853817416.192\n",
      "[28,  2000] loss: 1821827273.376\n",
      "[28,  3000] loss: 1828464684.672\n",
      "[28,  4000] loss: 1874422292.768\n",
      "[28,  5000] loss: 1849174409.888\n",
      "[28,  6000] loss: 1807631193.280\n",
      "[28,  7000] loss: 1883593595.616\n",
      "[28,  8000] loss: 1844444305.440\n",
      "[28,  9000] loss: 1802890518.016\n",
      "[29,  1000] loss: 1789880911.456\n",
      "[29,  2000] loss: 1821115755.904\n",
      "[29,  3000] loss: 1830993224.256\n",
      "[29,  4000] loss: 1827004172.192\n",
      "[29,  5000] loss: 1887971806.592\n",
      "[29,  6000] loss: 1858574564.416\n",
      "[29,  7000] loss: 1836983841.632\n",
      "[29,  8000] loss: 1855612885.344\n",
      "[29,  9000] loss: 1876786188.192\n",
      "[30,  1000] loss: 1822593502.816\n",
      "[30,  2000] loss: 1807841544.608\n",
      "[30,  3000] loss: 1841717715.360\n",
      "[30,  4000] loss: 1852818331.392\n",
      "[30,  5000] loss: 1830512163.264\n",
      "[30,  6000] loss: 1845261060.128\n",
      "[30,  7000] loss: 1888472205.760\n",
      "[30,  8000] loss: 1833025035.488\n",
      "[30,  9000] loss: 1859021662.640\n",
      "[31,  1000] loss: 1878487246.272\n",
      "[31,  2000] loss: 1866013022.144\n",
      "[31,  3000] loss: 1787218375.072\n",
      "[31,  4000] loss: 1790084573.952\n",
      "[31,  5000] loss: 1774261821.504\n",
      "[31,  6000] loss: 1872039572.608\n",
      "[31,  7000] loss: 1848879998.848\n",
      "[31,  8000] loss: 1856410681.408\n",
      "[31,  9000] loss: 1916409245.888\n",
      "[32,  1000] loss: 1832314303.136\n",
      "[32,  2000] loss: 1841639637.664\n",
      "[32,  3000] loss: 1859569795.168\n",
      "[32,  4000] loss: 1813017316.160\n",
      "[32,  5000] loss: 1858953200.704\n",
      "[32,  6000] loss: 1846230886.112\n",
      "[32,  7000] loss: 1782229869.664\n",
      "[32,  8000] loss: 1836060621.760\n",
      "[32,  9000] loss: 1856166727.136\n",
      "[33,  1000] loss: 1883318423.712\n",
      "[33,  2000] loss: 1821867498.784\n",
      "[33,  3000] loss: 1837823668.544\n",
      "[33,  4000] loss: 1868667507.424\n",
      "[33,  5000] loss: 1829929383.296\n",
      "[33,  6000] loss: 1854634688.896\n",
      "[33,  7000] loss: 1769298018.304\n",
      "[33,  8000] loss: 1805335321.056\n",
      "[33,  9000] loss: 1855561813.792\n",
      "[34,  1000] loss: 1836604180.736\n",
      "[34,  2000] loss: 1762235731.488\n",
      "[34,  3000] loss: 1843548614.624\n",
      "[34,  4000] loss: 1840961168.544\n",
      "[34,  5000] loss: 1869680771.136\n",
      "[34,  6000] loss: 1826929752.288\n",
      "[34,  7000] loss: 1788021227.776\n",
      "[34,  8000] loss: 1896065769.728\n",
      "[34,  9000] loss: 1854950473.152\n",
      "[35,  1000] loss: 1853250972.864\n",
      "[35,  2000] loss: 1825027797.408\n",
      "[35,  3000] loss: 1830769863.680\n",
      "[35,  4000] loss: 1794889552.736\n",
      "[35,  5000] loss: 1862507601.152\n",
      "[35,  6000] loss: 1837956558.048\n",
      "[35,  7000] loss: 1789701063.616\n",
      "[35,  8000] loss: 1858522274.944\n",
      "[35,  9000] loss: 1831666594.976\n",
      "[36,  1000] loss: 1859738414.720\n",
      "[36,  2000] loss: 1821655515.712\n",
      "[36,  3000] loss: 1812162357.344\n",
      "[36,  4000] loss: 1863505510.096\n",
      "[36,  5000] loss: 1771541564.224\n",
      "[36,  6000] loss: 1828637782.592\n",
      "[36,  7000] loss: 1832064834.912\n",
      "[36,  8000] loss: 1849791311.456\n",
      "[36,  9000] loss: 1829002802.528\n",
      "[37,  1000] loss: 1857450394.336\n",
      "[37,  2000] loss: 1816941111.296\n",
      "[37,  3000] loss: 1882570285.408\n",
      "[37,  4000] loss: 1820223232.480\n",
      "[37,  5000] loss: 1744888679.008\n",
      "[37,  6000] loss: 1789967550.176\n",
      "[37,  7000] loss: 1858843676.000\n",
      "[37,  8000] loss: 1892149388.032\n",
      "[37,  9000] loss: 1815449489.120\n",
      "[38,  1000] loss: 1820354346.304\n",
      "[38,  2000] loss: 1813189741.344\n",
      "[38,  3000] loss: 1855981186.560\n",
      "[38,  4000] loss: 1791038149.120\n",
      "[38,  5000] loss: 1832970741.440\n",
      "[38,  6000] loss: 1776360730.368\n",
      "[38,  7000] loss: 1815946050.208\n",
      "[38,  8000] loss: 1832771141.312\n",
      "[38,  9000] loss: 1875363508.928\n",
      "[39,  1000] loss: 1743027475.456\n",
      "[39,  2000] loss: 1845357673.088\n",
      "[39,  3000] loss: 1817519409.664\n",
      "[39,  4000] loss: 1829328353.664\n",
      "[39,  5000] loss: 1810320524.736\n",
      "[39,  6000] loss: 1806092346.976\n",
      "[39,  7000] loss: 1863389055.104\n",
      "[39,  8000] loss: 1861052705.600\n",
      "[39,  9000] loss: 1825307314.336\n",
      "[40,  1000] loss: 1806015294.464\n",
      "[40,  2000] loss: 1812178887.808\n",
      "[40,  3000] loss: 1811164744.800\n",
      "[40,  4000] loss: 1842870425.536\n",
      "[40,  5000] loss: 1781965480.992\n",
      "[40,  6000] loss: 1813500167.584\n",
      "[40,  7000] loss: 1838323205.568\n",
      "[40,  8000] loss: 1798093868.896\n",
      "[40,  9000] loss: 1864791014.432\n",
      "[41,  1000] loss: 1853543860.384\n",
      "[41,  2000] loss: 1808851865.248\n",
      "[41,  3000] loss: 1883081145.280\n",
      "[41,  4000] loss: 1824086585.920\n",
      "[41,  5000] loss: 1827441397.120\n",
      "[41,  6000] loss: 1813020882.816\n",
      "[41,  7000] loss: 1806570345.312\n",
      "[41,  8000] loss: 1776653576.032\n",
      "[41,  9000] loss: 1800264998.944\n",
      "[42,  1000] loss: 1791594593.248\n",
      "[42,  2000] loss: 1862078774.688\n",
      "[42,  3000] loss: 1831231912.864\n",
      "[42,  4000] loss: 1804905427.040\n",
      "[42,  5000] loss: 1830415908.160\n",
      "[42,  6000] loss: 1834362914.368\n",
      "[42,  7000] loss: 1825095182.816\n",
      "[42,  8000] loss: 1870270422.400\n",
      "[42,  9000] loss: 1757118527.936\n",
      "[43,  1000] loss: 1821656343.712\n",
      "[43,  2000] loss: 1791907200.576\n",
      "[43,  3000] loss: 1828567500.512\n",
      "[43,  4000] loss: 1827429764.192\n",
      "[43,  5000] loss: 1816287638.272\n",
      "[43,  6000] loss: 1791679153.312\n",
      "[43,  7000] loss: 1849355405.824\n",
      "[43,  8000] loss: 1833313218.480\n",
      "[43,  9000] loss: 1852647085.152\n",
      "[44,  1000] loss: 1824562656.736\n",
      "[44,  2000] loss: 1784307591.680\n",
      "[44,  3000] loss: 1820805043.296\n",
      "[44,  4000] loss: 1888269062.752\n",
      "[44,  5000] loss: 1789537366.048\n",
      "[44,  6000] loss: 1807964275.488\n",
      "[44,  7000] loss: 1828432148.608\n",
      "[44,  8000] loss: 1832503140.416\n",
      "[44,  9000] loss: 1764915743.616\n",
      "[45,  1000] loss: 1821689238.240\n",
      "[45,  2000] loss: 1820110294.144\n",
      "[45,  3000] loss: 1794767796.736\n",
      "[45,  4000] loss: 1834135225.120\n",
      "[45,  5000] loss: 1783976108.448\n",
      "[45,  6000] loss: 1886427863.648\n",
      "[45,  7000] loss: 1801820885.312\n",
      "[45,  8000] loss: 1813404583.712\n",
      "[45,  9000] loss: 1801185840.768\n",
      "[46,  1000] loss: 1851526846.432\n",
      "[46,  2000] loss: 1791408143.296\n",
      "[46,  3000] loss: 1777770777.248\n",
      "[46,  4000] loss: 1821839153.920\n",
      "[46,  5000] loss: 1835369972.480\n",
      "[46,  6000] loss: 1804369896.480\n",
      "[46,  7000] loss: 1824133451.168\n",
      "[46,  8000] loss: 1833648529.856\n",
      "[46,  9000] loss: 1784351832.224\n",
      "[47,  1000] loss: 1834790679.456\n",
      "[47,  2000] loss: 1784424329.984\n",
      "[47,  3000] loss: 1814669619.072\n",
      "[47,  4000] loss: 1825257055.232\n",
      "[47,  5000] loss: 1791093343.680\n",
      "[47,  6000] loss: 1850806487.808\n",
      "[47,  7000] loss: 1812165288.096\n",
      "[47,  8000] loss: 1844591532.576\n",
      "[47,  9000] loss: 1806273873.440\n",
      "[48,  1000] loss: 1843289504.800\n",
      "[48,  2000] loss: 1782139384.576\n",
      "[48,  3000] loss: 1848089384.768\n",
      "[48,  4000] loss: 1782539338.592\n",
      "[48,  5000] loss: 1825427210.144\n",
      "[48,  6000] loss: 1840050961.568\n",
      "[48,  7000] loss: 1803132127.424\n",
      "[48,  8000] loss: 1803051804.832\n",
      "[48,  9000] loss: 1782624606.368\n",
      "[49,  1000] loss: 1866816216.960\n",
      "[49,  2000] loss: 1856017896.416\n",
      "[49,  3000] loss: 1819037331.360\n",
      "[49,  4000] loss: 1798760633.376\n",
      "[49,  5000] loss: 1801748907.552\n",
      "[49,  6000] loss: 1812704493.632\n",
      "[49,  7000] loss: 1818531121.472\n",
      "[49,  8000] loss: 1800820977.856\n",
      "[49,  9000] loss: 1748599224.800\n",
      "[50,  1000] loss: 1841215698.080\n",
      "[50,  2000] loss: 1810351968.256\n",
      "[50,  3000] loss: 1776172458.592\n",
      "[50,  4000] loss: 1858767960.384\n",
      "[50,  5000] loss: 1816217499.200\n",
      "[50,  6000] loss: 1821122108.960\n",
      "[50,  7000] loss: 1776341213.280\n",
      "[50,  8000] loss: 1786088835.296\n",
      "[50,  9000] loss: 1815239264.672\n",
      "[51,  1000] loss: 1812201807.776\n",
      "[51,  2000] loss: 1819678943.168\n",
      "[51,  3000] loss: 1776164983.104\n",
      "[51,  4000] loss: 1786649397.536\n",
      "[51,  5000] loss: 1845762226.752\n",
      "[51,  6000] loss: 1801383015.040\n",
      "[51,  7000] loss: 1810561898.624\n",
      "[51,  8000] loss: 1823193388.896\n",
      "[51,  9000] loss: 1808131212.512\n",
      "[52,  1000] loss: 1794108840.864\n",
      "[52,  2000] loss: 1811024662.400\n",
      "[52,  3000] loss: 1840320427.552\n",
      "[52,  4000] loss: 1843318400.640\n",
      "[52,  5000] loss: 1780677795.488\n",
      "[52,  6000] loss: 1812589841.664\n",
      "[52,  7000] loss: 1798442750.368\n",
      "[52,  8000] loss: 1803366810.880\n",
      "[52,  9000] loss: 1794097307.360\n",
      "[53,  1000] loss: 1802110095.968\n",
      "[53,  2000] loss: 1782934093.600\n",
      "[53,  3000] loss: 1796496946.528\n",
      "[53,  4000] loss: 1835579373.600\n",
      "[53,  5000] loss: 1821389214.368\n",
      "[53,  6000] loss: 1800602816.288\n",
      "[53,  7000] loss: 1811758841.344\n",
      "[53,  8000] loss: 1799970724.544\n",
      "[53,  9000] loss: 1815197894.208\n",
      "[54,  1000] loss: 1806299151.392\n",
      "[54,  2000] loss: 1791287182.368\n",
      "[54,  3000] loss: 1851634366.432\n",
      "[54,  4000] loss: 1755442884.064\n",
      "[54,  5000] loss: 1810684790.944\n",
      "[54,  6000] loss: 1821513579.328\n",
      "[54,  7000] loss: 1850953446.144\n",
      "[54,  8000] loss: 1777797361.056\n",
      "[54,  9000] loss: 1805686037.472\n",
      "[55,  1000] loss: 1764416636.448\n",
      "[55,  2000] loss: 1833406247.264\n",
      "[55,  3000] loss: 1820640496.608\n",
      "[55,  4000] loss: 1798820118.016\n",
      "[55,  5000] loss: 1811498111.392\n",
      "[55,  6000] loss: 1801079803.776\n",
      "[55,  7000] loss: 1811327819.136\n",
      "[55,  8000] loss: 1789406074.240\n",
      "[55,  9000] loss: 1835367278.080\n",
      "[56,  1000] loss: 1834504905.632\n",
      "[56,  2000] loss: 1758749346.240\n",
      "[56,  3000] loss: 1774393820.896\n",
      "[56,  4000] loss: 1801792590.240\n",
      "[56,  5000] loss: 1836256609.216\n",
      "[56,  6000] loss: 1810383105.152\n",
      "[56,  7000] loss: 1827715237.024\n",
      "[56,  8000] loss: 1828056747.264\n",
      "[56,  9000] loss: 1773963275.712\n",
      "[57,  1000] loss: 1826178560.032\n",
      "[57,  2000] loss: 1805514368.640\n",
      "[57,  3000] loss: 1787012565.056\n",
      "[57,  4000] loss: 1789535142.496\n",
      "[57,  5000] loss: 1758094078.912\n",
      "[57,  6000] loss: 1802710686.720\n",
      "[57,  7000] loss: 1826915202.112\n",
      "[57,  8000] loss: 1823875084.544\n",
      "[57,  9000] loss: 1786796549.280\n",
      "[58,  1000] loss: 1828444709.952\n",
      "[58,  2000] loss: 1788113455.808\n",
      "[58,  3000] loss: 1800589100.416\n",
      "[58,  4000] loss: 1832061097.344\n",
      "[58,  5000] loss: 1812998052.448\n",
      "[58,  6000] loss: 1792541677.216\n",
      "[58,  7000] loss: 1774974749.472\n",
      "[58,  8000] loss: 1814940662.336\n",
      "[58,  9000] loss: 1797659185.536\n",
      "[59,  1000] loss: 1787972100.384\n",
      "[59,  2000] loss: 1813966026.272\n",
      "[59,  3000] loss: 1774698495.296\n",
      "[59,  4000] loss: 1836986361.424\n",
      "[59,  5000] loss: 1815980217.728\n",
      "[59,  6000] loss: 1728631236.576\n",
      "[59,  7000] loss: 1887144663.360\n",
      "[59,  8000] loss: 1806751390.944\n",
      "[59,  9000] loss: 1781337303.424\n",
      "[60,  1000] loss: 1834289761.184\n",
      "[60,  2000] loss: 1772720318.528\n",
      "[60,  3000] loss: 1783865934.176\n",
      "[60,  4000] loss: 1781989530.528\n",
      "[60,  5000] loss: 1795793840.928\n",
      "[60,  6000] loss: 1776427967.136\n",
      "[60,  7000] loss: 1834871483.968\n",
      "[60,  8000] loss: 1805917506.240\n",
      "[60,  9000] loss: 1818447997.120\n",
      "[61,  1000] loss: 1797207194.176\n",
      "[61,  2000] loss: 1840014348.640\n",
      "[61,  3000] loss: 1802269325.152\n",
      "[61,  4000] loss: 1807995772.320\n",
      "[61,  5000] loss: 1791996964.384\n",
      "[61,  6000] loss: 1800203456.192\n",
      "[61,  7000] loss: 1812496398.976\n",
      "[61,  8000] loss: 1734818670.528\n",
      "[61,  9000] loss: 1851130053.760\n",
      "[62,  1000] loss: 1838036583.456\n",
      "[62,  2000] loss: 1770854895.856\n",
      "[62,  3000] loss: 1817008456.544\n",
      "[62,  4000] loss: 1810649620.448\n",
      "[62,  5000] loss: 1803142244.928\n",
      "[62,  6000] loss: 1787848600.992\n",
      "[62,  7000] loss: 1804792770.880\n",
      "[62,  8000] loss: 1768031307.072\n",
      "[62,  9000] loss: 1780638730.752\n",
      "[63,  1000] loss: 1830066497.344\n",
      "[63,  2000] loss: 1754075734.592\n",
      "[63,  3000] loss: 1777103325.216\n",
      "[63,  4000] loss: 1859937220.816\n",
      "[63,  5000] loss: 1846239135.072\n",
      "[63,  6000] loss: 1790968657.440\n",
      "[63,  7000] loss: 1801853096.096\n",
      "[63,  8000] loss: 1759725514.432\n",
      "[63,  9000] loss: 1782165215.072\n",
      "[64,  1000] loss: 1787041903.616\n",
      "[64,  2000] loss: 1781501398.336\n",
      "[64,  3000] loss: 1785137096.320\n",
      "[64,  4000] loss: 1754830948.160\n",
      "[64,  5000] loss: 1821604603.200\n",
      "[64,  6000] loss: 1820000817.600\n",
      "[64,  7000] loss: 1844276585.888\n",
      "[64,  8000] loss: 1794022653.376\n",
      "[64,  9000] loss: 1799747251.968\n",
      "[65,  1000] loss: 1816365804.320\n",
      "[65,  2000] loss: 1785945694.848\n",
      "[65,  3000] loss: 1804878995.168\n",
      "[65,  4000] loss: 1794095505.760\n",
      "[65,  5000] loss: 1813878879.712\n",
      "[65,  6000] loss: 1780540927.520\n",
      "[65,  7000] loss: 1752652880.576\n",
      "[65,  8000] loss: 1844370707.936\n",
      "[65,  9000] loss: 1794505655.520\n",
      "[66,  1000] loss: 1745056671.712\n",
      "[66,  2000] loss: 1825263660.896\n",
      "[66,  3000] loss: 1798038711.168\n",
      "[66,  4000] loss: 1801339904.960\n",
      "[66,  5000] loss: 1798469197.216\n",
      "[66,  6000] loss: 1769133393.632\n",
      "[66,  7000] loss: 1818703243.008\n",
      "[66,  8000] loss: 1771105089.408\n",
      "[66,  9000] loss: 1841785212.160\n",
      "[67,  1000] loss: 1806500881.888\n",
      "[67,  2000] loss: 1841382998.592\n",
      "[67,  3000] loss: 1788181445.760\n",
      "[67,  4000] loss: 1795771621.088\n",
      "[67,  5000] loss: 1819367593.888\n",
      "[67,  6000] loss: 1788906460.544\n",
      "[67,  7000] loss: 1795074494.880\n",
      "[67,  8000] loss: 1754772488.096\n",
      "[67,  9000] loss: 1769706526.016\n",
      "[68,  1000] loss: 1813925996.992\n",
      "[68,  2000] loss: 1827149958.240\n",
      "[68,  3000] loss: 1786473640.032\n",
      "[68,  4000] loss: 1795768252.096\n",
      "[68,  5000] loss: 1824691710.624\n",
      "[68,  6000] loss: 1804885781.056\n",
      "[68,  7000] loss: 1761617703.232\n",
      "[68,  8000] loss: 1789291930.368\n",
      "[68,  9000] loss: 1743673334.688\n",
      "[69,  1000] loss: 1762466598.624\n",
      "[69,  2000] loss: 1786214566.880\n",
      "[69,  3000] loss: 1794108671.456\n",
      "[69,  4000] loss: 1781313494.368\n",
      "[69,  5000] loss: 1745592684.448\n",
      "[69,  6000] loss: 1812325642.496\n",
      "[69,  7000] loss: 1828763942.752\n",
      "[69,  8000] loss: 1800839204.352\n",
      "[69,  9000] loss: 1812105451.392\n",
      "[70,  1000] loss: 1856432415.776\n",
      "[70,  2000] loss: 1794857789.184\n",
      "[70,  3000] loss: 1777545868.832\n",
      "[70,  4000] loss: 1786716700.544\n",
      "[70,  5000] loss: 1778494100.928\n",
      "[70,  6000] loss: 1808874575.296\n",
      "[70,  7000] loss: 1770685441.568\n",
      "[70,  8000] loss: 1809039846.240\n",
      "[70,  9000] loss: 1744740584.096\n",
      "[71,  1000] loss: 1807994065.216\n",
      "[71,  2000] loss: 1769661323.488\n",
      "[71,  3000] loss: 1787804148.384\n",
      "[71,  4000] loss: 1764070313.184\n",
      "[71,  5000] loss: 1832076135.232\n",
      "[71,  6000] loss: 1812420774.976\n",
      "[71,  7000] loss: 1775974966.560\n",
      "[71,  8000] loss: 1815379699.072\n",
      "[71,  9000] loss: 1775718640.512\n",
      "[72,  1000] loss: 1750318666.144\n",
      "[72,  2000] loss: 1816179473.600\n",
      "[72,  3000] loss: 1785939819.136\n",
      "[72,  4000] loss: 1792487751.232\n",
      "[72,  5000] loss: 1808564366.528\n",
      "[72,  6000] loss: 1783121186.592\n",
      "[72,  7000] loss: 1807348524.128\n",
      "[72,  8000] loss: 1772517897.024\n",
      "[72,  9000] loss: 1798401951.328\n",
      "[73,  1000] loss: 1790723724.992\n",
      "[73,  2000] loss: 1806175140.704\n",
      "[73,  3000] loss: 1820003446.624\n",
      "[73,  4000] loss: 1763513646.880\n",
      "[73,  5000] loss: 1765260589.792\n",
      "[73,  6000] loss: 1778310148.128\n",
      "[73,  7000] loss: 1817542476.320\n",
      "[73,  8000] loss: 1770078950.784\n",
      "[73,  9000] loss: 1774978201.728\n",
      "[74,  1000] loss: 1789185375.200\n",
      "[74,  2000] loss: 1803543333.312\n",
      "[74,  3000] loss: 1805006168.512\n",
      "[74,  4000] loss: 1747199931.936\n",
      "[74,  5000] loss: 1799478292.640\n",
      "[74,  6000] loss: 1821955256.320\n",
      "[74,  7000] loss: 1812554555.968\n",
      "[74,  8000] loss: 1799438688.768\n",
      "[74,  9000] loss: 1739265457.184\n",
      "[75,  1000] loss: 1791162380.640\n",
      "[75,  2000] loss: 1815226497.408\n",
      "[75,  3000] loss: 1788747375.104\n",
      "[75,  4000] loss: 1791151566.528\n",
      "[75,  5000] loss: 1757351388.032\n",
      "[75,  6000] loss: 1818545348.736\n",
      "[75,  7000] loss: 1796210621.824\n",
      "[75,  8000] loss: 1767303610.784\n",
      "[75,  9000] loss: 1778352680.704\n",
      "[76,  1000] loss: 1751856242.368\n",
      "[76,  2000] loss: 1790835910.368\n",
      "[76,  3000] loss: 1808271280.992\n",
      "[76,  4000] loss: 1767491056.384\n",
      "[76,  5000] loss: 1792157216.512\n",
      "[76,  6000] loss: 1800835438.976\n",
      "[76,  7000] loss: 1795525202.960\n",
      "[76,  8000] loss: 1762384291.264\n",
      "[76,  9000] loss: 1823082496.992\n",
      "[77,  1000] loss: 1809756978.208\n",
      "[77,  2000] loss: 1767221177.216\n",
      "[77,  3000] loss: 1785038095.424\n",
      "[77,  4000] loss: 1792725067.072\n",
      "[77,  5000] loss: 1765878508.800\n",
      "[77,  6000] loss: 1766719067.040\n",
      "[77,  7000] loss: 1787354362.816\n",
      "[77,  8000] loss: 1789880297.120\n",
      "[77,  9000] loss: 1776324765.824\n",
      "[78,  1000] loss: 1841575192.928\n",
      "[78,  2000] loss: 1763128793.152\n",
      "[78,  3000] loss: 1810080486.592\n",
      "[78,  4000] loss: 1718726507.296\n",
      "[78,  5000] loss: 1824008206.432\n",
      "[78,  6000] loss: 1729812827.200\n",
      "[78,  7000] loss: 1810808135.232\n",
      "[78,  8000] loss: 1784502447.488\n",
      "[78,  9000] loss: 1807097305.984\n",
      "[79,  1000] loss: 1828533390.688\n",
      "[79,  2000] loss: 1724947626.656\n",
      "[79,  3000] loss: 1835865127.040\n",
      "[79,  4000] loss: 1778822827.392\n",
      "[79,  5000] loss: 1794950913.280\n",
      "[79,  6000] loss: 1796423991.520\n",
      "[79,  7000] loss: 1743001661.120\n",
      "[79,  8000] loss: 1778232679.168\n",
      "[79,  9000] loss: 1798324319.872\n",
      "[80,  1000] loss: 1832593199.840\n",
      "[80,  2000] loss: 1768289779.808\n",
      "[80,  3000] loss: 1791722513.920\n",
      "[80,  4000] loss: 1760840957.632\n",
      "[80,  5000] loss: 1794711257.088\n",
      "[80,  6000] loss: 1745183142.272\n",
      "[80,  7000] loss: 1751336664.864\n",
      "[80,  8000] loss: 1780873850.048\n",
      "[80,  9000] loss: 1800898704.160\n",
      "[81,  1000] loss: 1785811237.600\n",
      "[81,  2000] loss: 1796207377.504\n",
      "[81,  3000] loss: 1777294369.792\n",
      "[81,  4000] loss: 1780729080.096\n",
      "[81,  5000] loss: 1743704956.384\n",
      "[81,  6000] loss: 1836520128.640\n",
      "[81,  7000] loss: 1792809864.928\n",
      "[81,  8000] loss: 1789763613.280\n",
      "[81,  9000] loss: 1793238741.408\n",
      "[82,  1000] loss: 1766928538.240\n",
      "[82,  2000] loss: 1753085781.184\n",
      "[82,  3000] loss: 1787139257.408\n",
      "[82,  4000] loss: 1793615954.784\n",
      "[82,  5000] loss: 1872286923.488\n",
      "[82,  6000] loss: 1780136646.848\n",
      "[82,  7000] loss: 1763599226.784\n",
      "[82,  8000] loss: 1758655719.488\n",
      "[82,  9000] loss: 1787651770.880\n",
      "[83,  1000] loss: 1788590964.160\n",
      "[83,  2000] loss: 1757831852.544\n",
      "[83,  3000] loss: 1803253726.848\n",
      "[83,  4000] loss: 1775553022.496\n",
      "[83,  5000] loss: 1779361978.416\n",
      "[83,  6000] loss: 1845011927.776\n",
      "[83,  7000] loss: 1771841917.952\n",
      "[83,  8000] loss: 1802985046.336\n",
      "[83,  9000] loss: 1763317003.024\n",
      "[84,  1000] loss: 1801610600.896\n",
      "[84,  2000] loss: 1757174655.392\n",
      "[84,  3000] loss: 1791649984.832\n",
      "[84,  4000] loss: 1802097575.168\n",
      "[84,  5000] loss: 1795596916.736\n",
      "[84,  6000] loss: 1776426744.256\n",
      "[84,  7000] loss: 1786406868.512\n",
      "[84,  8000] loss: 1816347944.224\n",
      "[84,  9000] loss: 1758218115.232\n",
      "[85,  1000] loss: 1835289535.968\n",
      "[85,  2000] loss: 1755578111.104\n",
      "[85,  3000] loss: 1783362538.656\n",
      "[85,  4000] loss: 1785889374.720\n",
      "[85,  5000] loss: 1813350951.328\n",
      "[85,  6000] loss: 1769347993.312\n",
      "[85,  7000] loss: 1806109908.288\n",
      "[85,  8000] loss: 1748879485.344\n",
      "[85,  9000] loss: 1749652269.856\n",
      "[86,  1000] loss: 1771929012.032\n",
      "[86,  2000] loss: 1766113134.464\n",
      "[86,  3000] loss: 1803532088.960\n",
      "[86,  4000] loss: 1761995967.136\n",
      "[86,  5000] loss: 1799045532.640\n",
      "[86,  6000] loss: 1772776891.968\n",
      "[86,  7000] loss: 1807404392.288\n",
      "[86,  8000] loss: 1783494351.104\n",
      "[86,  9000] loss: 1773869389.344\n",
      "[87,  1000] loss: 1751525089.440\n",
      "[87,  2000] loss: 1821816503.328\n",
      "[87,  3000] loss: 1817992427.008\n",
      "[87,  4000] loss: 1777396878.016\n",
      "[87,  5000] loss: 1754012587.648\n",
      "[87,  6000] loss: 1769420542.208\n",
      "[87,  7000] loss: 1768165032.448\n",
      "[87,  8000] loss: 1747033374.592\n",
      "[87,  9000] loss: 1812062076.288\n",
      "[88,  1000] loss: 1811580267.392\n",
      "[88,  2000] loss: 1799221596.192\n",
      "[88,  3000] loss: 1812921464.832\n",
      "[88,  4000] loss: 1768533086.752\n",
      "[88,  5000] loss: 1725057221.216\n",
      "[88,  6000] loss: 1786607875.584\n",
      "[88,  7000] loss: 1798115511.392\n",
      "[88,  8000] loss: 1785764047.104\n",
      "[88,  9000] loss: 1751673864.736\n",
      "[89,  1000] loss: 1783414599.296\n",
      "[89,  2000] loss: 1736788668.640\n",
      "[89,  3000] loss: 1791865569.504\n",
      "[89,  4000] loss: 1782029559.392\n",
      "[89,  5000] loss: 1798955191.936\n",
      "[89,  6000] loss: 1797443192.032\n",
      "[89,  7000] loss: 1779964222.592\n",
      "[89,  8000] loss: 1758931202.048\n",
      "[89,  9000] loss: 1759965024.448\n",
      "[90,  1000] loss: 1823458761.120\n",
      "[90,  2000] loss: 1821138235.168\n",
      "[90,  3000] loss: 1774453170.720\n",
      "[90,  4000] loss: 1772211289.824\n",
      "[90,  5000] loss: 1723137307.648\n",
      "[90,  6000] loss: 1822046474.848\n",
      "[90,  7000] loss: 1769289692.960\n",
      "[90,  8000] loss: 1765868352.352\n",
      "[90,  9000] loss: 1765191285.536\n",
      "[91,  1000] loss: 1770903265.600\n",
      "[91,  2000] loss: 1794850515.136\n",
      "[91,  3000] loss: 1760510417.536\n",
      "[91,  4000] loss: 1789913996.480\n",
      "[91,  5000] loss: 1792768540.736\n",
      "[91,  6000] loss: 1735771405.920\n",
      "[91,  7000] loss: 1822312674.368\n",
      "[91,  8000] loss: 1794189293.056\n",
      "[91,  9000] loss: 1763128985.504\n",
      "[92,  1000] loss: 1760209455.488\n",
      "[92,  2000] loss: 1786353773.952\n",
      "[92,  3000] loss: 1861695898.656\n",
      "[92,  4000] loss: 1781516582.944\n",
      "[92,  5000] loss: 1763594353.440\n",
      "[92,  6000] loss: 1792837385.728\n",
      "[92,  7000] loss: 1766708755.744\n",
      "[92,  8000] loss: 1749462435.104\n",
      "[92,  9000] loss: 1779147020.736\n",
      "[93,  1000] loss: 1795258807.520\n",
      "[93,  2000] loss: 1747450061.056\n",
      "[93,  3000] loss: 1756326548.384\n",
      "[93,  4000] loss: 1810155417.344\n",
      "[93,  5000] loss: 1773530725.472\n",
      "[93,  6000] loss: 1759028307.120\n",
      "[93,  7000] loss: 1730081430.160\n",
      "[93,  8000] loss: 1793420182.336\n",
      "[93,  9000] loss: 1830337854.272\n",
      "[94,  1000] loss: 1788081474.368\n",
      "[94,  2000] loss: 1746233756.896\n",
      "[94,  3000] loss: 1775885826.240\n",
      "[94,  4000] loss: 1770979627.808\n",
      "[94,  5000] loss: 1776016906.176\n",
      "[94,  6000] loss: 1803252296.320\n",
      "[94,  7000] loss: 1770047166.336\n",
      "[94,  8000] loss: 1753367188.576\n",
      "[94,  9000] loss: 1805234489.664\n",
      "[95,  1000] loss: 1747569457.568\n",
      "[95,  2000] loss: 1806056273.536\n",
      "[95,  3000] loss: 1775327848.928\n",
      "[95,  4000] loss: 1797005741.056\n",
      "[95,  5000] loss: 1811537579.504\n",
      "[95,  6000] loss: 1781250613.600\n",
      "[95,  7000] loss: 1739010743.872\n",
      "[95,  8000] loss: 1756621322.592\n",
      "[95,  9000] loss: 1772272698.368\n",
      "[96,  1000] loss: 1788485005.120\n",
      "[96,  2000] loss: 1805302244.096\n",
      "[96,  3000] loss: 1800001283.872\n",
      "[96,  4000] loss: 1821211340.512\n",
      "[96,  5000] loss: 1772226200.768\n",
      "[96,  6000] loss: 1755234440.128\n",
      "[96,  7000] loss: 1774160437.824\n",
      "[96,  8000] loss: 1743914008.544\n",
      "[96,  9000] loss: 1771266781.824\n",
      "[97,  1000] loss: 1752605839.072\n",
      "[97,  2000] loss: 1793804024.704\n",
      "[97,  3000] loss: 1799336378.112\n",
      "[97,  4000] loss: 1751765749.696\n",
      "[97,  5000] loss: 1774296612.160\n",
      "[97,  6000] loss: 1754864635.200\n",
      "[97,  7000] loss: 1816368795.808\n",
      "[97,  8000] loss: 1761218639.104\n",
      "[97,  9000] loss: 1791114430.800\n",
      "[98,  1000] loss: 1774331653.440\n",
      "[98,  2000] loss: 1724233490.752\n",
      "[98,  3000] loss: 1783623884.448\n",
      "[98,  4000] loss: 1811871224.448\n",
      "[98,  5000] loss: 1749368799.872\n",
      "[98,  6000] loss: 1807056020.608\n",
      "[98,  7000] loss: 1779164406.048\n",
      "[98,  8000] loss: 1784926180.000\n",
      "[98,  9000] loss: 1765626940.576\n",
      "[99,  1000] loss: 1796864481.120\n",
      "[99,  2000] loss: 1723915297.856\n",
      "[99,  3000] loss: 1791076839.040\n",
      "[99,  4000] loss: 1771005718.400\n",
      "[99,  5000] loss: 1774367667.232\n",
      "[99,  6000] loss: 1757982330.560\n",
      "[99,  7000] loss: 1817443490.976\n",
      "[99,  8000] loss: 1761023443.808\n",
      "[99,  9000] loss: 1763458806.976\n",
      "[100,  1000] loss: 1757984766.880\n",
      "[100,  2000] loss: 1801546820.864\n",
      "[100,  3000] loss: 1754059571.840\n",
      "[100,  4000] loss: 1776592289.952\n",
      "[100,  5000] loss: 1797588116.160\n",
      "[100,  6000] loss: 1757284206.464\n",
      "[100,  7000] loss: 1782484414.944\n",
      "[100,  8000] loss: 1763177298.336\n",
      "[100,  9000] loss: 1814245663.424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr =1e-5)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# trainLoader = trainLoader.to(device)\n",
    "\n",
    "\n",
    "print(\"Epochs Started\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\trunning_loss = 0.0\n",
    "\tfor i, data in enumerate(trainLoader):\n",
    "\t\tX, y = data\n",
    "\t\ty = y.unsqueeze(1)\n",
    "\t\t# X = X.to(device)\n",
    "\t\t# y = y.to(device)\n",
    "  \n",
    "\t\tnet.zero_grad()\n",
    "\n",
    "\n",
    "\t\toutput = net(X)\n",
    "\n",
    "\t\tloss = criterion(output, y)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 1000 == 999:    # print every 1000 mini-batches\n",
    "\t\t\tprint(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "\t\t\trunning_loss = 0.0\n",
    "\n",
    "torch.save(net.state_dict(), modelPath)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (input): Linear(in_features=573, out_features=128, bias=True)\n",
       "  (hidden1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (hidden3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newNet = Net()\n",
    "# load model state dict\n",
    "newNet.load_state_dict(torch.load(modelPath))\n",
    "newNet = newNet.to(device)\n",
    "\n",
    "# test\n",
    "newNet.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
