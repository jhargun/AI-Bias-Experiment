{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(573, 2048)\n",
    "        self.hidden1 = nn.Linear(2048, 1024)\n",
    "        self.hidden2 = nn.Linear(1024, 512)\n",
    "        self.hidden3 = nn.Linear(512, 256)\n",
    "        self.hidden4 = nn.Linear(256, 128)\n",
    "        self.hidden5 = nn.Linear(128, 64)\n",
    "        self.hidden6 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        x = F.relu(self.hidden4(x))\n",
    "        x = F.relu(self.hidden5(x))\n",
    "        x = F.relu(self.hidden6(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables Definintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = int(time.time())\n",
    "useCUDA = True\n",
    "dataPath = \"../large_field_preprocessed_data.csv\"\n",
    "epochs = 50\n",
    "batchSize = 32\n",
    "modelPath = f\"../trained_models/{t}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if not useCUDA:\n",
    "\tdevice = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net = net.to(device)\n",
    "\n",
    "\n",
    "trainSet = torch.load(\"../dataset/trainSet.pt\")\n",
    "trainLoader = DataLoader(trainSet, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs Started\n",
      "[1,  1000] loss: 4402729116.480\n",
      "[1,  2000] loss: 2992651744.416\n",
      "[1,  3000] loss: 3014048884.224\n",
      "[1,  4000] loss: 2783807846.432\n",
      "[1,  5000] loss: 2922727249.376\n",
      "[1,  6000] loss: 2833529335.744\n",
      "[1,  7000] loss: 2753362227.616\n",
      "[1,  8000] loss: 2839281310.080\n",
      "[1,  9000] loss: 2675294500.064\n",
      "[1, 10000] loss: 2788983097.216\n",
      "[1, 11000] loss: 2765732781.312\n",
      "[1, 12000] loss: 2608823484.064\n",
      "[1, 13000] loss: 2542186785.296\n",
      "[1, 14000] loss: 2599845117.440\n",
      "[1, 15000] loss: 2528826241.952\n",
      "[1, 16000] loss: 2515833738.752\n",
      "[1, 17000] loss: 2465628904.224\n",
      "[1, 18000] loss: 2305377943.360\n",
      "[1, 19000] loss: 2155122806.288\n",
      "[1, 20000] loss: 2370942224.624\n",
      "[1, 21000] loss: 2193116138.416\n",
      "[1, 22000] loss: 2321080503.776\n",
      "[1, 23000] loss: 2265057340.464\n",
      "[1, 24000] loss: 2116005688.992\n",
      "[1, 25000] loss: 2194132947.328\n",
      "[1, 26000] loss: 2206054497.136\n",
      "[1, 27000] loss: 2057425385.952\n",
      "[1, 28000] loss: 2206997738.128\n",
      "[1, 29000] loss: 2109864402.976\n",
      "[1, 30000] loss: 2158060804.720\n",
      "[1, 31000] loss: 1963388754.688\n",
      "[1, 32000] loss: 2076960309.328\n",
      "[1, 33000] loss: 2048365951.088\n",
      "[1, 34000] loss: 1876774801.920\n",
      "[1, 35000] loss: 2063310822.528\n",
      "[1, 36000] loss: 1941630538.960\n",
      "[1, 37000] loss: 2047687165.056\n",
      "[1, 38000] loss: 1962988308.720\n",
      "[1, 39000] loss: 1925878760.224\n",
      "[1, 40000] loss: 2007985647.280\n",
      "[2,  1000] loss: 1917006932.368\n",
      "[2,  2000] loss: 1968682600.624\n",
      "[2,  3000] loss: 2024403549.424\n",
      "[2,  4000] loss: 1918645410.512\n",
      "[2,  5000] loss: 1921685199.160\n",
      "[2,  6000] loss: 2092414683.376\n",
      "[2,  7000] loss: 1943552292.752\n",
      "[2,  8000] loss: 1877189360.752\n",
      "[2,  9000] loss: 1937635531.816\n",
      "[2, 10000] loss: 1875877799.888\n",
      "[2, 11000] loss: 1786682176.848\n",
      "[2, 12000] loss: 1906971359.008\n",
      "[2, 13000] loss: 1959363221.040\n",
      "[2, 14000] loss: 2024430619.232\n",
      "[2, 15000] loss: 1877694894.640\n",
      "[2, 16000] loss: 1850651322.976\n",
      "[2, 17000] loss: 1857446390.240\n",
      "[2, 18000] loss: 1950669267.744\n",
      "[2, 19000] loss: 1865865811.840\n",
      "[2, 20000] loss: 1971833516.048\n",
      "[2, 21000] loss: 1951288575.056\n",
      "[2, 22000] loss: 1824204338.432\n",
      "[2, 23000] loss: 1809431200.688\n",
      "[2, 24000] loss: 1911935692.736\n",
      "[2, 25000] loss: 1848869391.168\n",
      "[2, 26000] loss: 1861321271.664\n",
      "[2, 27000] loss: 1890714531.056\n",
      "[2, 28000] loss: 1799284210.752\n",
      "[2, 29000] loss: 1865057922.336\n",
      "[2, 30000] loss: 1968803925.056\n",
      "[2, 31000] loss: 1796742016.432\n",
      "[2, 32000] loss: 1933554213.152\n",
      "[2, 33000] loss: 1848927318.432\n",
      "[2, 34000] loss: 1784290072.928\n",
      "[2, 35000] loss: 1790140527.904\n",
      "[2, 36000] loss: 1882734788.688\n",
      "[2, 37000] loss: 1907067889.424\n",
      "[2, 38000] loss: 1869740406.544\n",
      "[2, 39000] loss: 1838498869.920\n",
      "[2, 40000] loss: 1885418343.648\n",
      "[3,  1000] loss: 1772055505.424\n",
      "[3,  2000] loss: 1812152926.720\n",
      "[3,  3000] loss: 1879520728.320\n",
      "[3,  4000] loss: 1845350935.888\n",
      "[3,  5000] loss: 1881436204.880\n",
      "[3,  6000] loss: 1963452140.272\n",
      "[3,  7000] loss: 1747645384.608\n",
      "[3,  8000] loss: 1907701354.528\n",
      "[3,  9000] loss: 1882454756.480\n",
      "[3, 10000] loss: 1881934641.040\n",
      "[3, 11000] loss: 1762183920.224\n",
      "[3, 12000] loss: 1794519188.256\n",
      "[3, 13000] loss: 1841883020.688\n",
      "[3, 14000] loss: 1666131489.936\n",
      "[3, 15000] loss: 1858705012.176\n",
      "[3, 16000] loss: 1833016692.704\n",
      "[3, 17000] loss: 1858609021.568\n",
      "[3, 18000] loss: 1829169780.016\n",
      "[3, 19000] loss: 1724580744.944\n",
      "[3, 20000] loss: 1753711460.528\n",
      "[3, 21000] loss: 1842933286.960\n",
      "[3, 22000] loss: 1865201140.424\n",
      "[3, 23000] loss: 1872694991.104\n",
      "[3, 24000] loss: 1849625562.592\n",
      "[3, 25000] loss: 1729200159.336\n",
      "[3, 26000] loss: 1745147217.968\n",
      "[3, 27000] loss: 1897130232.816\n",
      "[3, 28000] loss: 1843809612.736\n",
      "[3, 29000] loss: 1952142681.600\n",
      "[3, 30000] loss: 1757782664.800\n",
      "[3, 31000] loss: 1784620838.592\n",
      "[3, 32000] loss: 1798911548.896\n",
      "[3, 33000] loss: 1816381677.184\n",
      "[3, 34000] loss: 1860497952.872\n",
      "[3, 35000] loss: 1899428896.624\n",
      "[3, 36000] loss: 1966181861.856\n",
      "[3, 37000] loss: 1819998457.632\n",
      "[3, 38000] loss: 1757271670.544\n",
      "[3, 39000] loss: 1806121513.992\n",
      "[3, 40000] loss: 1842800826.448\n",
      "[4,  1000] loss: 1783705817.304\n",
      "[4,  2000] loss: 1824726500.672\n",
      "[4,  3000] loss: 1817591849.760\n",
      "[4,  4000] loss: 1829318599.568\n",
      "[4,  5000] loss: 1736252898.560\n",
      "[4,  6000] loss: 1809298247.408\n",
      "[4,  7000] loss: 1831204812.512\n",
      "[4,  8000] loss: 1812558375.296\n",
      "[4,  9000] loss: 1773765129.488\n",
      "[4, 10000] loss: 1793819534.728\n",
      "[4, 11000] loss: 1768564039.344\n",
      "[4, 12000] loss: 1828604487.144\n",
      "[4, 13000] loss: 1879897637.888\n",
      "[4, 14000] loss: 1875461415.808\n",
      "[4, 15000] loss: 1771292400.896\n",
      "[4, 16000] loss: 1798485789.504\n",
      "[4, 17000] loss: 1853283428.648\n",
      "[4, 18000] loss: 1786083876.000\n",
      "[4, 19000] loss: 1854371543.456\n",
      "[4, 20000] loss: 1783653245.008\n",
      "[4, 21000] loss: 1755495815.320\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr =1e-5)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "print(\"Epochs Started\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\trunning_loss = 0.0\n",
    "\tfor i, data in enumerate(trainLoader):\n",
    "\t\tX, y = data\n",
    "\t\ty = y.unsqueeze(1)\n",
    "\t\tX = X.to(device)\n",
    "\t\ty = y.to(device)\n",
    "\n",
    "\t\tnet.zero_grad()\n",
    "\n",
    "\t\toutput = net(X)\n",
    "\n",
    "\t\tloss = criterion(output, y)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tif i % 1000 == 999:    # print every 1000 mini-batches\n",
    "\t\t\tprint(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "\t\t\trunning_loss = 0.0\n",
    "\n",
    "torch.save(net.state_dict(), modelPath)\n",
    "torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
